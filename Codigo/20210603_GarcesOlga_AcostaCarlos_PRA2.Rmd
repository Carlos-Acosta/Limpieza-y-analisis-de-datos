---
title: '**M2.851 – TIPOLOGÍA Y CICLO DE VIDA DE LOS DATOS: PRA 2**'
author: "Olga Garcés Ciemerozum / Carlos Acosta Quintas"
date: "Junio 2021"
geometry: margin=2cm
output:
  #pdf_document:
    #toc: yes
    #toc_depth: '4'

  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 4
---

<style>
body {
text-align: justify}
</style>


  
```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, fig.align="center")
knitr::opts_chunk$set(fig.align="center", echo = TRUE, tidy=TRUE )
options(width = 500)

```

  



```{r load_libraries, message=FALSE, warning=FALSE, include=FALSE}
# Cargamos las librerias de  R que vamos a usar
library(rpart.plot) #CART
library(caret) #CART

library(lattice)
library("ISLR")
library("SmartEDA")
library("tidyverse")
library(DT) # Para visualizar tablas
library(VIM)
library(readr)
library(plyr)
library (MASS)
library(grid)
library(ggpubr) # Para QQ plot
library(ggplot2) # Para graficos
# library(stringr) #Para str_to_title()
# library(reshape) #Para Pivot Tables
# library(VIM) # Para kNN
library(psych) # Para Grafico Correlaciones
library(pastecs) #Para tabla resumen cuantitativa
library(gmodels) #Para tabla resumen cualiativa
library(knitr) #Para Kable
library(kableExtra) #Para Kable
library(hrbrthemes) #Para gráficos densidades
library(dplyr) #Para gráficos densidades
library(vioplot) #Para gráficos violin
library(PASWR) #Estadístico z
library(BSDA) #Estadístico z.test
library(lsr) #Eta2
library(faraway) #Multicolinealidad
library(gridExtra) #Grid graficas
library(corrplot) #Plot para correlaciones
library(ResourceSelection) #Hosmer Lemeshowi
library(InformationValue) #ROC
library(plotROC)#ROC
library(DescTools) #Scheffe test
```

<br><br><br>



  
# Introducción{-}

  

El presente informe forma parte de la segunda práctica de la asignatura M2.851 - Tipología y ciclo de vida de los datos del Máster Universitario en Ciencia de Datos impartido por la Universitat Oberta de Catalunya.  
  
En esta práctica se realizarán técnicas de limpieza de datos aplicadas a un juego de datos determinado y también se analizarán dichos datos para extraer información relevante y útil.  
  
A su vez, se entregará, junto con la presente memoria, una serie de archivos con el código necesario para la realización de la limpieza y análisis con el que el usuario podrá realizar diferentes estudios analíticos a posteriori si lo desease.
  
  



******
# **Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?**
******
  
## **Descripción del dataset**

<br>

  
El dataset Titanic reune los datos sobre los pasajeros que viajaban a bordo del Titanic y registra para cada persona su supervivencia o no en el accidente. El Titanic transportaba a pasajeros con gran diversidad en sus niveles de renta y edad y a bordo se encontraban familias enteras.
  

La etiqueta (variable a predecir) es la variable dicotómica que indica si el viajero ha sobrevivido o no.

  
La ubicación en kaggle del dataset utilizado se muestra en el siguiente link:
  
https://www.kaggle.com/c/titanic/data
  
Los archivos disponibles son 3 y están en formato csv. Sus nombres son:
  
•	train.csv  
•	test.csv  
•	gender_submission.csv: Ejemplo a seguir en la entrega de la competición Kaggle (no útil).  
  

Según los registros, en el Titanic viajaban **2229 personas**, de las cuales 913 formaban parte de la tripulación del barco. El dataset que obtenemos de Kaggle tiene un total de **1309 registros**, por lo tanto, no todos los pasajeros que viajaban a bordo están incluidos en el dataset y podemos asumir que **el juego de datos es una muestra de toda la población a analizar**.
  

El dataset original está compuesto por dos ficheros: el fichero pensado para realizar el entrenamiento de un modelo (**train.csv**) y el fichero con los datos destinados a testear la calidad del modelo (**test.csv**). El fichero de entrenamiento contiene una columna más que el fichero de prueba. Esta columna corresponde a la columna de la clase "Survived".   
  
El fichero de entrenamiento tiene **891** registros mientras que el fichero de test contiene **418** instancias.  
  
<br>

Las variables de las que se compone el dataset son y sus unidades o magnitudes de las características son: 
  
**PassengerId**:  
Identificador del pasajero  
Tipo: Entero indicando un identificador único de casa instancia.  
  
<p>

**Survived**:  
Indica si el pasajero ha sobrevivido la catástrofe  
Tipo: Entero (categórica) 0 = No ha sobrevivido; 1 = Ha sobrevivido  
  
<p>

**Pclass**:  
Clase en la que viajaba el pasajero  
Tipo: String (categórica) 1 = Primera clase; 2 = Segunda clase; 3 = Tercera Clase  
  
<p>

**Name**:  
Nombre del pasajero  
Tipo: String  
  
<p>

**Sex**:  
Sexo del pasajero  
Tipo: String (categórica) female = Mujer; male = hombre  
  
<p>

**Age**:  
Edad del pasajero  
Tipo: Entero  
  
<p>

**SibSp**:  
Indica si el pasajero tenía hermanos o pareja a bordo  
Tipo: Entero  
  
<p>

**Parch**:  
Indica si el pasajero tenía padres o hijos a bordo  
Tipo: Entero  
  
<p>
        
**Ticket**:  
Número del billete  
Tipo: String alfanumérico  
  
<p>
 
**Fare**:  
Precio del billete sin especificar si es un billete individual o grupal  
Tipo: Número Real  
  

**Cabin**:  
Número de camarote  
Tipo: String  
  
<p>
        
**Embarked**:  
Indica si el pasajero ha embarcado o no y donde  
Tipo: String (categórica) C = Cherbourg; Q = Queenstown; S = Southampton  


<br>
      
Los datos no han pasado por un proceso de preprocesado o limpieza, por lo que aún pueden existir inconsistencias y el formato no es necesariamente el más adecuado para un análisis directo.
  
  
<br>  
  
**Carga del dataset**:
  
Cargamos el dataset y mostramos sus dimensiones, estructura y tipo de datos:
  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Carga de los archivos que contienen los datos del train y test
test <- read.csv("dataset_titanic/test.csv")
train <- read.csv("dataset_titanic/train.csv")

train_rows <- dim(train)
test_rows <- dim(test)

train_rows
test_rows
```

  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estructura de los archivos train.csv y test.csv
str(train)
str(test)
```
  

<br>

Visualizamos las primeras líneas del conjunto de entrenamiento y de test.  


<br>  
  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}

kbl(head(train),booktabs =T)%>%
  kable_styling(latex_options =c("striped","scale_down"))

kbl(head(test),booktabs =T)%>%
  kable_styling(latex_options =c("striped","scale_down"))
```
  
  







## **¿Por qué es importante el dataset?**

<br>
  
Este dataset es importante porque nos permite esclarecer qué factores pudieron influir en la supervivencia de viajeros del Titanic y obtener el conocimiento necesario para poder hacer predicciones con nuevas instancias.  
  
Estos factores intuimos que pueden ser el estatus social, el sexo, la edad y también tener familiares cerca. 
  
Asimismo, podemos ver si las pautas marcadas por la sociedad de "mujeres y niños primero" se cumplen cuando las personas se encuentran en situaciones de estres extremo.
  
De igual forma, y en el ámbito de la ciencia de datos, este dataset es importante porque es considerado un clásico y ha ayudado a muchos estudiantes a enfrentarse por primera vez a un problema de limpieza de datos, análisis estadísticos e incluso a técnicas de machine learning.
  
  
<br>

## **¿Qué problema pretende responder el dataset?**
  
<br>

Este dataset pretende responder a cuáles son los diferentes factores que afectaron a la posibilidad de supervivencia de personas en el accidente del Titanic.
  
  

******
# **Integración y selección de los datos**
******

  
  
## **Integración de los Datos**

<br>

  
La integración es un proceso que forma parte de la fase de limpieza de datos y se entiende como la fusión de datos para crear una estructura única que tenga la información necesaria para el posterior análisis de datos.
  
Existe la integración horizontal, que básicamente se compone de la adición de nuevos atributos a partir de otras fuentes mediante sus relaciones usando claves primarias y la integración vertical, que se basaría en añadir más instancias al juego de datos (siempre manteniendo la integridad de los atributos).  
  
En nuestro caso, tenemos dos archivos **train.csv** y **test.csv**, dónde la diferencia entre ambos es que el test no tiene las etiquetas de la variable “Survived”.

<br>

  
**Integración Vertical**:
  
Con la finalidad de observar las distribuciones de las variables que serán base del estudio en la predicción de **“Survived”** integraremos verticalmente los dos archivos y así obtendremos un mayor número de datos **para ver sus medidas de tendencia central y dispersión.**  
  
Para que la integración vertical sea satisfactoria, las variables y estructura de ambos archivos debe coincidir, por tanto, crearemos un dataframe **train_sin_etiqueta** que se integrará con las instancias de test.csv al cual llamaremos **df_total_sin_etiqueta**.  
  
Observamos que la integración es satisfactoria puesto que las instancias ahora son **1309 (891 + 418)**. Generaremos a su vez un nuevo archivo csv auxiliar que mostrará este dataframe **"Titanic_global_sin_etiqueta.csv"**

  
  





```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación archivo train_sin_etiqueta.csv

etiquetas <- subset(train, select = Survived)
train_sin_etiqueta <- subset(train, select = -Survived)

# Integración archivos train.csv y test.csv
df_total_sin_etiqueta = rbind(train_sin_etiqueta, test)
dim(df_total_sin_etiqueta)

# Guardamos el archivo con el nombre Titanic_global_sin_etiqueta.csv
write.csv(df_total_sin_etiqueta, "Titanic_global_sin_etiqueta.csv", row.names = FALSE)
```
  
<br>

**Integración Horizontal**:
  
Los archivos en la plataforma Kaggle no exponen ni fuentes externas ni csv adicionales que definan nuevas variables que se puedan integrar horizontalmente a nuestro juego de datos.  
  
<br>  


**Comprobación de líneas duplicadas**:

  

Comprobamos si hay líneas duplicadas en el dataframe usando `duplicated`. No existen registros duplicados, pero sí detectamos dos pares de personas con el mismo nombre. **Para asegurarnos que se trata de personas diferentes**, buscamos los registros que tengan los nombres Connolly, Miss. Kate o Kelly, Mr. James.   
  
Podría tratarse de la misma persona que ha comprado dos billetes, pero en estos registros vemos que las personas tienen edades diferentes y no hay motivo para pensar que se trata de duplicados.  
  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Chequeo de líneas duplicadas
df_total_sin_etiqueta[duplicated(df_total_sin_etiqueta),]

df_total_sin_etiqueta[duplicated(df_total_sin_etiqueta[c("Name","Sex")]),]
df_total_sin_etiqueta[df_total_sin_etiqueta$Name=="Kelly, Mr. James" |
                        df_total_sin_etiqueta$Name == "Connolly, Miss. Kate",]

```
  
  

## **Selección de los Datos**

<br>
  
La selección se puede entender como un primer filtro de los datos, no solamente a través de poner límites a los valores de algunas instancias o elegir algún valor cualitativo específico, sino también a través de la inspección de las correlaciones entre los atributos y la posterior eliminación del dataset de aquellos que sean redundantes.
  
**Debido a que el problema planteado es interpretar qué factores influyen en la supervivencia, a priori, no sabríamos si debemos descartar alguna variable o no (eliminación de la variable del estudio) o si deberíamos filtrar los datos, ya sean numérica o categóricamente.**
  
No obstante, en esta sección eliminaremos la variable **“Name”** porque no es de mucha utilidad para nuestros análisis ya que el nombre no debería influir a priori en la supervivencia de los viajeros y también la variable **“PassengerId”**puesto que simplemente es un identificador.
  

Por lo tanto, además de esta primera selección relizada, **esta fase del proceso la dejaremos abierta en este punto y retomaremos una vez la exploración y análisis nos vaya indicando qué debemos seleccionar y/o filtrar**. A continuación, se hace una lista de las selecciones realizadas en este apartado y a posteriori.
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos variables Name
keep.cols <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Ticket", "Fare", "Cabin", "Embarked")
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```

<br>

Variable Modificada | Tipo de selección | Apartado realizado | Motivo
------------------- | ----------------- | ------------------ | ------
Name|Eliminación|2.2|Variable no útil al ser independiente al estudio
PassengerId|Eliminación|2.2|Variable no útil al ser un simple identificador
Ticket|Eliminación|2.3|Usada para crear nueva variable y ya no es útil
Fase|Eliminación|2.3|Usada para crear nueva variable y ya no es útil
Cabin|Eliminación|3.1|Existencia masiva de valores nulos	

<br>
  
## **Creación de nuevas variables**
  
<br>

Se ha detectado que **hay números de billetes duplicados**. Esto indica que hay dos tipos de tickets:
  
•	**Individuales**  
•	**Grupales**
  
<br>


Se observa que la variable **“Fare”** muestra el mismo precio para los tickets grupales, por tanto, para saber realmente el precio del ticket por viajero y también para poder usar correctamente la variable “Fare”, **deberíamos saber de cuántas personas es el ticket grupal y después dividir la variable “Fare” for dicha cantidad**.
  
Crearemos una columna con el recuento de billetes (**Count.ticket**) con el mismo id para cada pasajero y otra con el precio unitario (**Unit.price**).

  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación variable con el contaje de los tickets con mismo nombre
df_total_sin_etiqueta$Count.ticket <- (df_total_sin_etiqueta%>%
                                         group_by(Ticket)%>%
                                         mutate(count=n()))$count
```

  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación variable con el precio unitario de los tickets con mismo nombre
df_total_sin_etiqueta$Unit.price <- df_total_sin_etiqueta$Fare / df_total_sin_etiqueta$Count.ticket
```

  
  


Selección de datos inicial a posteriori
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos variable Name
keep.cols <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Cabin",
               "Embarked", "Count.ticket", "Unit.price")

df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```

  
<br>

Ahora disponemos de una variable consistente con el precio del billete y que se puede aplicar a cada viajero, **pues la tarifa grupal se ha convertido en individual.**<p>




******
# **Limpieza de datos**
******


<br>

**NOTA:** <p>

Hay que mencionar que se la limpieza de datos en este proyecto en particular **debe afectar tanto al archivo train.csv como al test.csv**, por tanto, limpiaremos los datos en base al dataframe global creado anteriormente (**df_total_sin_etiqueta**).

<br>

## **¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?**

  
### **Elementos vacíos en el dataset**

<br>
  
Comprobaremos si existen valores nulos o inexistentes en el juego de datos. 
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Exploración de los datos - Type = 1

kbl(ExpData(data=df_total_sin_etiqueta,type=1),booktabs =T)%>%
  kable_styling(latex_options =c("striped"))

# Estructura de los datos - Type = 2

kbl(ExpData(data=df_total_sin_etiqueta,type=2),booktabs =T)%>%
  kable_styling(latex_options =c("striped","scale_down"))
```
  
Una vez que sabemos que tenemos valores nulos, cuántos tenemos y sabemos las variables afectadas, se decide la estrategia para imputar dichos valores.<p>

<br>

  
  
**Variable Cabin**:
  
Observamos que la variable “Cabin” tiene 1014 valores nulos de 1309, por tanto, se decide eliminar dicha variable por la imposibilidad de realizar una imputación generalizada.

<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos variable Cabin
keep.cols <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Embarked", "Count.ticket", "Unit.price")
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```

<br>
  
**Variable Age**:
  
El número de registros de Age que son NA representan aproximadamente el 20% de los registros totales. 
  
Este dataset contiene variables categóricas y numéricas y para imputar los valores nulos de la variable Age podemos usar **el método `kNN`**. Aplicamos la función e imputamos los valores NA usando todos los demás campos del dataset y con un valor de k igual a 3. El algoritmo busca los registros de los 3 pasajeros más parecidos (cercanos según la distancia Gower) al que contiene un valor nulo y usa los datos de edades de estos pasajeros para imputar el valor faltante.
  
Una vez ejecutado el algoritmo para imputar los valores, volvemos a comprobar si existen valores NA y **podemos confirmar que todos los NA para la variable edad han sido imputados**.

  







```{r echo=TRUE, message=FALSE, warning=FALSE}
# Imputación de valores a los valores nulos de la variable age
df_total_sin_etiqueta <- kNN(df_total_sin_etiqueta, k=3)[1:10]

head(df_total_sin_etiqueta[is.na(df_total_sin_etiqueta$Age),])
```
  
  


```{r echo=TRUE, message=FALSE, warning=FALSE}
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```
  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Comprobacion de la no existencia de registros nulos para la variable age después de la imputación.
sum(is.na(df_total_sin_etiqueta$Age))
```
  
<br>

**Variable Embarked**:
  
Se observa que la mayoría de las instancias pertenecen a la categoría S, por tanto, las instancias con valores nulos en esta variable, las imputaremos a S.

  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Exploración del resumen de los datos de la varibale Embarked 
df_total_sin_etiqueta$Embarked <- as.factor(df_total_sin_etiqueta$Embarked)
summary(df_total_sin_etiqueta$Embarked)
```
  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Imputación clase mayoritaria a variable Embarked 
df_total_sin_etiqueta$Embarked[df_total_sin_etiqueta$Embarked == ""] <- "S"
summary(df_total_sin_etiqueta$Embarked)
```
  
  
<br>

**Variable Unit.price**:
  

Actuaremos de igual forma que con la variable Age e imputaremos a través del uso del kNN

  

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Imputación de valores a los valores nulos de la variable age
df_total_sin_etiqueta <- kNN(df_total_sin_etiqueta, k=3)[1:10]
head(df_total_sin_etiqueta[is.na(df_total_sin_etiqueta$Unit.price),])

df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```


<br>


  
  

### **Gestión de los valores iguales a “cero” en el dataset**:

<br>

Ahora comprobamos las variables que toman valores igual a cero sin que tenga sentido que tomen este tipo de valor.   
  
La variable que representa las "etiquetas" (variable **Survived**) toma valores iguales a cero y consideramos que es correcto puesto que es parte de la variable dicotómica del dataset. Lo mismo ocurre con las variables **SibSp**, **Parch**, donde consideramos normal que existan valores iguales a cero, **significa que los pasajeros no tenían familia a bordo o viajaban solos**.  
  
En cambio, los valores iguales a cero para la variable **Unit.price** son algo más extraños. Entre los pasajeros que tienen un Unit.price igual a cero hay personas que viajaban en primera, segunda y tercera clase.  
  
**La idea que un ticket sea gratuito, en principio, no sería posible**, por tanto, volveremos a aplicar el método kNN para imputar estos valores.  
  
Primero cambiaremos el valor de cero a NA y después actuaremos como en el apartado anterior.
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
df_total_sin_etiqueta$Unit.price[df_total_sin_etiqueta$Unit.price == "0"] <- NA

# Imputación de valores a los valores ceros de la variable Unit.price
df_total_sin_etiqueta <- kNN(df_total_sin_etiqueta, k=3)[1:10]

head(df_total_sin_etiqueta[is.na(df_total_sin_etiqueta$Unit.price),])

df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

# Comprobacion de la no existencia de registros ceros para 
# la variable Unit.price después de la imputación.
sum(is.na(df_total_sin_etiqueta$Unit.price))
```

  
  

<br>

**Valores extremos** 
  
No hemos encontrado valores que estén fuera de un rango razonable. Las comprobaciones las hemos hecho anteriormente con `sapply(df, summary)`.  
  
Volvemos a visualizar boxplots para las variables numéricas que tenemos: **Age** y **Unit.price**.  

   

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}

oldpar = par(mfrow = c(1,2), mar=c(2,2,2,2))

# Boxplot variable Age
boxplot(df_total_sin_etiqueta$Age,
        main="Boxplot Variable Age",
        ylab="Edad (años)")

# Boxplot variable Unit.price
boxplot(df_total_sin_etiqueta$Unit.price,
        main="Boxplot Variable Unit.price",
        ylab="Precio billete unitario")
```
  
<br>  
  
Boxplot Stats Variable Age<p> 
  
```{r}
#Boxplot Stats Variable Age
boxplot.stats(df_total_sin_etiqueta$Age, coef = 1.5, do.conf = TRUE, do.out = TRUE)

```  

<br> 

Boxplot Stats Variable Unit.price<p>

```{r}
#Boxplot Stats Variable Fare
boxplot.stats(df_total_sin_etiqueta$Unit.price, coef = 1.5, do.conf = TRUE, do.out = TRUE)
```
  
  


El boxplot muestra que hay outliers en estas dos variables. La mayoría de los pasajeros eran jóvenes, aunque también encontramos pasajeros de más de 65 años. En cuanto a la variable **Unit.price**, se comprueba que a medida que el precio sube, la clase va bajando de 3 a 2 y de 2 a 1, con lo cual no hay razón porqué pensar que los precios no son reales. En la tabla siguiente podemos visualizar algunos de los pasajeros que pagaron un precio de billete alto. Notamos que todos son de primera clase.
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Muestra de varios precios de billetes unitarios en el rango alto

kbl(tail(df_total_sin_etiqueta[df_total_sin_etiqueta$Unit.price>30,], 15),booktabs =T)%>%
  kable_styling(latex_options =c("striped","scale_down"))
```
  
  

Aunque se acepte que los precios son reales, es cierto que hay uno que es extremadamente alto y, aunque cierto, podría desvirtuar posibles futuras predicciones, por tanto se estima que se podría cambiar por **la media de Unit.price agrupado por la primera clase**, para tener un valor imputado **más real**.  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Imputación del valor máximo de Unit.price
df_price_Pclass <- aggregate(df_total_sin_etiqueta$Unit.price ~ df_total_sin_etiqueta$Pclass,
                             df_total_sin_etiqueta, mean)
mean_Unit.price <- df_price_Pclass[2][[1]][1]

```
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Muestra de varios precios de billetes unitarios en el rango alto
max_Unit.price <- max(df_total_sin_etiqueta$Unit.price)
max_Unit.price

df_total_sin_etiqueta$Unit.price[df_total_sin_etiqueta$Unit.price == max_Unit.price] <- mean_Unit.price
mean_Unit.price
```
  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}

oldpar = par(mfrow = c(1,2), mar=c(2,2,1,1))

# Boxplot variable Age
boxplot(df_total_sin_etiqueta$Age,
        main="Boxplot Variable Age",
        ylab="Edad (años)")




# Boxplot variable Unit.price
boxplot(df_total_sin_etiqueta$Unit.price, 
        main="Boxplot Variable Unit.price",
        ylab="Precio billete unitario")


```
  
  
<br>

Observamos que hemos eliminado el valor extremo (el máximo) de Unit.price.<p>


******
# **Análisis de datos**
******

<br> 

Una vez limpiado el único archivo que contenía las líneas de los conjuntos train y test, **deberemos separar otra vez los conjuntos ya que únicamente tenemos datos de la etiqueta para el conjunto de entrenamiento**.

  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Guardamos en disco el archivo global
write.csv(df_total_sin_etiqueta, "Titanic_global_sin_etiqueta.csv", row.names = FALSE)

```
  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación del conjunto de train y test después de la limpieza del dataset
train <- df_total_sin_etiqueta[1:train_rows, ]
test <- df_total_sin_etiqueta[(train_rows + 1):(train_rows+test_rows), ]

```
  
  

Y añadimos las etiquetas al conjunto de train:
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Adición de las etiquetas al conjunto de entrenamiento
train <- cbind(train, etiquetas )
```

  
Una vez llegados a este punto, **guardamos en disco los archivos train y test procesados y "limpios" preparados para su posterior análisis**.
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Guardamos en disco los archivos procesados
write.csv(train, "train_processed.csv", row.names = FALSE)
write.csv(test, "test_processed.csv", row.names = FALSE)
```

<br> 
<br> 
  
## **Screening**  
  
Antes de crear las visualizaciones determinamos que las variables numéricas que son potencialmente importantes para el análisis son:  **Age** y **Unit.price** que corresponden a la edad de los pasajeros y el precio unitario del billete.  
  
**OLGA: revisar aquí, si las variables son categóricas o no, parece que nos va mejor que no lo sean**

**CARLOS: POR MI OK COMO ESTA, SI DECIDIMOS OK HAY QUE BORRAR LAS LINEAS COMENTADAS EN EL BLOQUE**

  
Survived, Sex, Embarked son variables categóricas y Pclass, SibSp, Parch son variables categóricas ordinales (existen rangos en los valores de las variables).  
  
Realizamos las transformaciones oportunas para guardar las variables con sus tipos correspondientes.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Categóricas
train$Survived <- as.factor(train$Survived)
train$Sex <- as.factor(train$Sex)

# Categóricas ordinales
#train$Pclass <- factor(train$Pclass, levels= c(1, 2, 3))
#train$SibSp <- factor(train$SibSp, levels = c(0, 1, 2, 3, 4, 5, 8))
#train$Parch <- factor(train$Parch, levels = c(0, 1, 2, 3, 4, 5, 6, 9))

```
  
  

Creamos una función que nos facilite visualizar las distribuciones de las variables. Se mostrará su histograma con su media (en rojo) y su mediana (en azul), su gráfico Q-Q y su boxplot filtrado for la variable etiqueta (Survived).
  
```{r echo=TRUE, message=FALSE, warning=FALSE}

visualiz <- function(data, colm, facet.colm, title, facetPlot=FALSE){
oldpar = par(mfrow = c(2,2), mar=c(2,2,2,2))
truehist(data[[colm]], main = title)
abline(v = mean(data[[colm]]), col="red", lwd=3, lty=2);
abline(v = median(data[[colm]]), lwd=3, lty=2, col="blue");
qqnorm(data[[colm]], main = title);qqline(data[[colm]], col = 2 )
if (facetPlot==TRUE) {
  boxplot(data[[colm]]~data[[facet.colm]], main = paste("Survived by", title))
}

boxplot(data[[colm]], main = title)
}
```
  
<br> 

**Visualización de las variables numéricas Age y Unit.price**  
  
Los pasajeros que tienen edades entre los cuantiles 25 y 75 tienen entre 20 y 40 años. La edad mediana para los pasajeros que sobrevivieron y los que no es muy similar.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz(train, "Age", "Survived", "Age", facetPlot=TRUE)
```

  
<br> 

Si observamos la variable **Unit.price**(precio unitario del billete), la mayoría de los pasajeros pagaron muy poco por el billete. Aquí en el boxplot encontramos outliers pero, como se ha comentado en el apartado anterior, consideramos solamente eliminar el máximo y no descartar el resto de estas entradas ya que hay pocos pasajeros que pagaron un importe alto por el billete y esta información puede ser muy interesante para predecir la posibilidad de supervivencia: ¿Viajar en una clase privilegiada aumenta la posibilidad de sobrevivir?  
  
En el boxplot además podemos ver que las personas que sobreviven tienen una mediana más alta en el precio del billete. 
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz(train, "Unit.price", "Survived", "Unit.price", facetPlot=TRUE)
```
  

**Visualización de las variables Class, Sex, Siblings/Spouse, Parents/Children**   

<br>

A continuación visualizamos los datos para las variables Class, Sex, Siblings/Spouse, Parents/Children:

<p>

**Color Naranja**:       Indica que el pasajero ha sobrevivido a la catástrofe  
**Color Negro**:        Indica que el pasajero **NO** ha sobrevivido a la catástrofe  

<br>
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
oldpar = par(mfrow = c(2,3), mar=c(2,2,2,2))

plot(table(train$Pclass, train$Survived),
     col = c("black", "orange"), main="Class")

plot(table(train$Sex, train$Survived),
     col = c("black", "orange"), main="Sex")

plot(table(train$SibSp, train$Survived),
     col = c("black", "orange"), main="Siblings/Spouse")

plot(table(train$Parch, train$Survived),
     col = c("black", "orange"), main="Parents/Children")

plot(table(train$Embarked, train$Survived),
     col = c("black", "orange"), main="Embarked")

plot(table(train$Count.ticket, train$Survived),
     col = c("black", "orange"), main="Ticket Count")

```
  
  


Las personas que viajaban en tercera clase tienen la menor proporción de supervivencia comparando con las personas que viajaban en primera clase. Las mujeres que viajaban en el titanic sobrevivieron en su mayoría. Los hombres sobrevivieron en mucho menor proporción.   
  
La mayoría de personas viajaba sin familiares (hermanos, pareja, padres o hijos) y parece ser que el porcentaje de supervivencia es algo más alto en personas que tenían familiares a bordo.   
  
La mayoría de personas embarcaron en el punto S, pero el mayor porcentaje de supervivencia lo tienen las personas que embarcaron en C.  
  
Los pasajeros que viajaban varias personas con el mismo billete también tienen una mayor supervivencia ( hasta 4 pasajeros ). 1 o más de 4 pasajeros con el mismo billete tienen la misma proporción de supervivencia.  

<br> 
  
**Análisis bivariable**  
  
Vamos a visualizar algunos plots que nos permiten ver la supervivencia de pasajeros combinando dos variables.<p>

<br>

**En función de la variable Clase**
<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}

grid.newpage()

sex.class <- ggplot(data=train, aes(x=Sex, fill=Survived))+
  geom_bar(position = 'fill')+
  facet_wrap(~Pclass)+
  scale_fill_manual(values=c("black", "orange"))

sibs.class <- ggplot(data=train, aes(x=SibSp, fill=Survived))+
  geom_bar(position = 'fill')+
  facet_wrap(~Pclass)+
  scale_fill_manual(values=c("black", "orange"))


parch.class <- ggplot(data=train, aes(x=Parch, fill=Survived))+
  geom_bar(position = 'fill')+
  facet_wrap(~Pclass)+
  scale_fill_manual(values=c("black", "orange"))

embark.class <- ggplot(data=train, aes(x=Embarked, fill=Survived))+
  geom_bar(position = 'fill')+
  facet_wrap(~Pclass)+
  scale_fill_manual(values=c("black", "orange"))

grid.arrange(sex.class, sibs.class, parch.class, embark.class,  ncol=2)

```
  
  

Las mujeres que viajaban en primera y segunda clase sobrevivieron casi todas. Los hombres sobrevivieron en mucho menor medida, incluso los hombres que viajaron en primera clase.  
  
Las personas que viajaban con hermanos o pareja en primera clase sobrevivieron en mayor medida que las personas que viajaron solas. En primera y segunda clase no hay personas que viajasen con más de 3 hermanos. En tercera clase hay personas que viajaron con hasta 8 hermanos en este caso un menor número de hermanos (excepto cero) parece indicar una mayor supervivencia.  


<br>

**CARLOS: COMENTAMOS LA GRAFICA SEXO, CLASE, EMBARQUE O LA ELIMINAMOS? POR MI LA ELIMINAMOS, NO PROBLEM**

<BR>

**En función de la localización de Embarque, Clase y Sexo**
<br>


También hemos visualizado la supervivencia en función del lugar donde los pasajeros embarcaron en el Titanic. Los pasajeros de tercera clase que embarcaron en el punto S han tenido menos proporción de supervivencia que los demás. Los pasajeros de segunda clase que embarcaron en Q sobrevivieron en mayor proporción que los pasajeros de segunda clase que embarcaron en otros puntos. Para los pasajeros de primera clase el punto de embarque con mayor porcentaje de superviviencia es C.   

<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data=train, aes(x=Sex, fill=as.factor(Pclass)))+
  geom_bar(position = 'fill')+
  facet_wrap(~Embarked)+
  scale_fill_manual(values=c("black", "orange", "red"))
```
  
  
```{r}
ggplot(data=train, aes(x=Embarked, fill=as.factor(Survived)))+geom_bar(position = 'fill')+
  scale_fill_manual(values=c("black", "orange", "red"))
```
  
  

Visualizamos la supervivencia usando las variables de la clase en la que viaja el pasajero y el número de personas que viajan con el mismo billete.  
  
En el Titanic viajaron familias enteras de hasta 7 personas en primera clase e incluso de 11 personas en tercera clase. La supervivencia de personas que viajaban sobre el mismo billete en tercera clase es comparable con el mismo dato en segunda clase.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data=train, aes(x=Count.ticket, fill=Survived))+
  geom_bar(position = 'fill')+
  facet_wrap(~Pclass)+
  scale_fill_manual(values=c("black", "orange", "red"))
```

  
  
## **Análisis de los datos.** 

  
### **Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).**  
  
La pregunta que planteamos inicialmente es si entre las variables que tenemos en el dataset existen algunas que influyen en mayor medida en la supervivencia de los pasajeros del Titanic. En los análisis anteriores hemos comprobado que:<p>

<br>

**-Visualmente que las personas de primera clase han sobrevivido en mayor medida**<p>
**-Las mujeres y los niños tienen una mayor proporción de supervivencia**<p>
**-Las personas que viajan acompañadas, ya sea por familia o amigos, tiene una proporcion de supervivencia algo mejor**<p>   
  
<br>

Vamos a usar estos datos para analizar el dataset en mayor profundidad. Para ello necesitamos datasets especializados.  


OLGA: Si seguimos con lo que hemos hablado, de centrarnos en si los pasajeros viajan solos o no, debemos separar estos 3 pares de datasets.**las variables sibsp, parch están como factor, voy a comentar la parte donde se les transforma en factor..** 
**CARLOS: OK**


<br>

**CARLOS: BORRAR, OK?**

<br>


  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por pasajeros que viajaban solos o acompañados
#train.single <- train[train$Count.ticket=="1",]
#train.many <- train[train$Count.ticket>1,]
```
 
 
<br>

**CARLOS: BORRAR, OK?**

<br>


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por pasajeros que viajaban solos o acompañados
#train.spouse <- train[train$SibSp>0,]
#train.not.spouse <- train[train$sibsp==0,]
```
  

<br>

**CARLOS: BORRAR, OK?**

<br> 
  
  
  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por pasajeros que viajaban solos o acompañados
#train.children <- train[train$Parch>10,]
#train.no.children <- train[train$Parch==0,]
```


<br>

**CARLOS: BORRAR, OK?**

<br>


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframes por clase de pasajero
#train.first <- train[train$Pclass==1,]
#train.second <- train[train$Pclass==2,]
#train.first.second <- train[train$Pclass==1 | train$Pclass==2,]
#train.first.second$Pclass <- factor(train.first.second$Pclass, levels = c(1,2))
```
 
 
<br>

**Subconjunto Hombres Vs. Mujeres**

<br>
 
 
 
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por sexo del pasajero
train.male <- train[train$Sex=="male", ]
train.female <- train[train$Sex=="female",]
```
  
  
<br>

**Subconjunto Jóvenes (<18 años) Vs. Adultos**

<br>


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por edad del pasajero
train.young <- train[train$Age<18,]
train.older <- train[train$Age>=18,]
```
  

<br>

**Subconjunto Supervivientes Vs. No Supervivientes**

<br>

  

```{r echo=TRUE, message=FALSE, warning=FALSE}
train.survived <- train[train$Survived==1,]
train.not.survived <- train[train$Survived==0,]
```


<br>

**Subconjunto Billete Único Vs. Billete Grupal**

<br>

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Tabla de contingencia Survived - Tipo Billete

train$ticket_tipo[train$Count.ticket==1] = "Único"
train$ticket_tipo[train$Count.ticket!=1] = "Grupal"

train$ticket_tipo <- as.factor(train$ticket_tipo)
```




<br> 

**Preparación de datos para aplicar algoritmos (Regresión logística, árboles de decisión, random forest).**:<p>



Los datos de test que tenemos no disponen de etiqueta de clase. 

Partimos el conjunto train en subconjuntos de train y validación. De esta manera dispondremos de datos para comprobar el funcionamiento de los modelos que construyamos.  

  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Variables independientes
X <- train[c("Pclass", "Sex", "Age", "SibSp", "Parch",
             "Count.ticket", "Unit.price", "Embarked")]

# Etiquetas de clase
y <- train[9]

```

  

```{r echo=TRUE, message=FALSE, warning=FALSE}
set.seed(3)
indexes = sample(1:nrow(train), size=floor((2/3)*nrow(train)))
trainX<-X[indexes,]
trainy<-y[indexes,]
validX<-X[-indexes,]
validy<-y[-indexes,]
```

<br>

Para algunos modelos necesitaremos la variable en forma de texto, por lo tanto guardamos un dato alternativo sobre la supervivencia de los pasajeros: **"Survived" para el valor 1 y "Died" para el valor 0** de la variable dependiente.  

<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
train$survived <- ifelse(train$Survived==1, "Survived", "Died")
```

<br>

Preparamos los datos para el algoritmo de Random Forest:<p>

<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Para random forest
y.1 <- train[10]
trainy.1 <- y.1[indexes,]
validy.1 <- y.1[-indexes,]
```
  
<br>

Para la regresión logística es mejor tener todos los datos juntos en un dataframe:

<br>

```{r echo=TRUE, message=FALSE, warning=FALSE}
regr.data <- data.frame(cbind(trainX, trainy))
```



### **Comprobación de la normalidad y homogeneidad de la varianza.**  
  
Función para visualizar los datos por pares.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
 visualiz1 <- function(D1, D2, name1, name2, title){
   oldpar = par(mfrow = c(2,2), mar=c(2,2,2,2))
  truehist(D1, main = paste(name1," ", title))
  abline(v = mean(D1), col="red", lwd=3, lty=2);
  abline(v = median(D1), lwd=3, lty=2, col="blue");
  qqnorm(D1, main = paste(name1, " ", title));qqline(D1, col = 2 )
  truehist(D2, main = paste(name2," ", title))
  abline(v = mean(D2), col="red", lwd=3, lty=2);
  abline(v = median(D2), lwd=3, lty=2, col="blue");
  qqnorm(D2, main = paste(name2," ", title)); qqline(D2, col = 2 )

}
```
  
<br> 

**Variable age**
  
Visualizamos los datos de la edad para personas que sobrevivieron en el hundimiento frente a personas que no sobrevivieron.  
  
La media (en rojo) y la mediana (en azul) de los pasajeros que sobrevivieron están muy cerca. Las personas que no sobrevivieron tienen una edad mediana más baja que la edad media. Los valores de estos dos indicadores de tendencia central son más altos para personas que no sobrevivieron: **las personas que murieron tenían una media de edad algo más alta que los que sobrevivieron**.  
  
Según el qqplot las dos distribuciones son cercanas a la normal.<p>

**Según el teorema del límite central podemos asumir la distribución normal de la media de estas dos muestras ya que sus tamaños son mayores que 30 observaciones.** 
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz1(train.survived$Age, train.not.survived$Age,
          "Survived", "Not Survived", "")
```
  
<br>

Comprobaremos de la igualdad de las varianzas entre los conjuntos de datos de pasajeros que sobrevivieron y no. Para ello usamos la función `var.test`.  
  
El contraste de varianzas se realiza mediante un contraste de hipótesis, donde aceptar H0 significaría que las varianzas son iguales. 
  
El valor **p-value** que obtenemos es de **0.15**. Este valor indica que rechazando la hipótesis nula de igualdad de varianzas probablemente estaríamos comentiendo un error, por tanto:<p>


**-Las varianzas en la edad de los pasajeros que sobrevivieron y los que no sobrevivieron son iguales y podemos hacer esta afirmación con un nivel de confianza del 95%.**

<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Age, train.not.survived$Age)
```
  
<br> 

**Variable Unit price: precio del billete unitario** 
  
Visualizamos el precio del billete unitario para los pasajeros que sobrevivieron frente a los que no. Podemos ver que la media (en rojo) y la mediana (en azul) del precio de billete para los pasajeros que sobrevivieron están bastante separadas. El precio que corresponde a la mediana es alrededor de **13** y la media es más cercana a **20**. Existe esta diferencia porque la distribución tiene una cola larga a la derecha, tenemos pasajeros que pagaron un precio muy alto por sus billetes.  
  
La mayoría de los pasajeros que no sobrevivieron pagaron un precio bajo por el billete, hay pocas personas que pagaron precios más altos y no sobrevivieron. 
  
Ninguna de las dos distribuciones es normal, aunque para el fin de hacer un contraste de hipótesos sobre la media podemos asumir que la media poblacional se distribuye normalmente (**Teorema del límite central**).  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz1(train.survived$Unit.price, train.not.survived$Unit.price,
          "Survived", "Not Survived", "Unit price")
```

  
  
Realizamos el test de igualdad de las varianzas para el precio del billete para pasajeros que sobrevivieron frente a los que no sobrevivieron. El valor **p-value** nos indica que podemos rechazar H0, es decir, **las varianzas entre estos dos grupos de pasajeros son diferentes**.  
  
En los histogramas podemos ver que los pasajeros que sobrevivieron de media pagaron más por sus billetes. Tanto en el grupo de supervivientes como de no supervivientes la media es mayor que la mediana, dado que tenemos outliers de precio de billete unitario muy alto.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Unit.price, train.not.survived$Unit.price)
```
  
  
<br>

**Variable SibSp: pareja o hermanos**  
  
Aunque la variable no sigue una distribución normal, dado el tamaño grande de la muestra podemos asumir que la media muestral sí sigue una distribución normal (**Teorema del límite central**)
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz1(train.survived$SibSp, train.not.survived$SibSp,
          "Survived", "Not Survived", "Siblings / Spouse")
```

  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$SibSp, train.not.survived$SibSp)
```
  
<br>
 
**Variable Parch: padres o hijos** 
  
Asumimos la normalidad de distribución de la media muestral aplicando el **Teorema del límite central**.  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz1(train.survived$Parch, train.not.survived$Parch,
          "Survived", "Not Survived", "Parents/Children")
```
  
  
El test de igualdad de las varianzas indica que **no podemos rechazar la hipótesis nula**. Entre los grupos que sobrevivieron y los que no sobrevivieron las varianzas de la variable Parch **son iguales**.  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Parch, train.not.survived$Parch)
```
  
<br> 

**Variable Count.ticket: número de personas que viajaban con un mismo billete**  
  
Visualizamos un histograma que muestra la frecuencia de recuento de billetes: pasajeros que viajaban solos hasta pasajeros que viajaban con muchos acompañantes.  
  
La media para el recuento de billetes es de **2** mientras que la mediana es **1**. 
  
Otra vez, aplicamos el **Teorema del límite central** y asumimos la normalidad de la distribución de las medias muestrales.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}

visualiz1(train.survived$Count.ticket, train.not.survived$Count.ticket, "Survived", "Not Survived", "Ticket count")
```
  
  
En este caso tenemos un valor **p-value** muy bajo y por lo tanto **podemos aceptar H1 que indica que las varianzas de la variable Count.ticket son diferentes** en el grupo de supervivientes y no supervivientes.  
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Count.ticket, train.not.survived$Count.ticket)
```
  


### **Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.**   

  
En esta práctica nos hemos planteado como objetivo encontrar cuales de las variables tuvieron una mayor influencia sobre la supervivencia de los pasajeros del Titanic. En este apartado aplicaremos varios contrastes de hipótesis, regresiones logísticas y también modelos de aprendizaje no supervisado (árboles de decisión y random forest).  
  

Las tareas que nos hemos planteado se muestran a continuación:  


<br>

**1.** Buscaremos correlaciones entre las variables del dataset.<p>

<br>

**2.** Realizaremos contrastes de hipótesis para responder a las siguientes preguntas:  

<br>

* **¿La proporción de hombres supervivientes es igual a la de mujeres supervivientes?**<p>
* **¿La proporción de menores supervivientes es igual a la proporción de mayores de edad que sobrevivieron?**<p>
* **¿La proporción de supervivientes entre los pasajeros que viajaban solos es igual a la proporción de supervivientes entre pasajeros que viajaban con más de una persona?**<p>
* **¿Las personas que sobrevivieron eran más jóvenes que las que no sobrevivieron?**<p>

<br>

**3.** Realizaremos un test Xi cuadrado para comprobar si:

<br>


* **Existe relación entre el tipo de billete (único o grupal) y la supervivencia de los distintos pasajeros**<p> 
* **Existe relación entre la clase en la que viajaban los pasajeros y su supervivencia.**<p>

<br>

 

**4.** Planteamos las siguientes regresiones logísticas:

<br>

* **Variable dependiente Survived explicada por la variable Sex**<p> 
* **Variable dependiente Survived explicada por las variables Sex y Pclass**<p>
* **Variable dependiente Survived explicada por todas las variables independientes disponibles.**<p>  

<br>

**5.** Aplicaremos un modelo de **árbol de decisión CART** con y sin validación cruzada y boosting.  

<br>

**6.** Aplicaremos un algoritmo de **Random Forest**. 

<br>








**1. --> Correlaciones**

  
```{r echo=TRUE, message=FALSE, warning=FALSE}

# Relaciones cruzadas de las variables cuantitativas (correlaciones) para todos los datos.
col_var_cuantitativa_sin_ID <- c("Age", "SibSp", "Parch", "Count.ticket", "Unit.price")

df_var_cuantitativa <- df_total_sin_etiqueta[, col_var_cuantitativa_sin_ID]

pairs.panels(df_var_cuantitativa[,col_var_cuantitativa_sin_ID], 
             method = "pearson", 
             hist.col = "grey",
             density = TRUE,  
             ellipses = TRUE 
             )

```

  
<br>

No se observa a priori ninguna correlación fuerte entre ninguna de las variables numéricas, aunque se puede notar cierta relación entre el número de tickets (**Count.ticket**) grupales y las variables **SibS** y **Parch**, suceso lógico pues estas variables indican que los viajeros iban acompañados y por tanto es lógico pensar que compartían mismo billete múltiple.<p>

<br>

El precio unitario del billete (**Unit.price**) versus la edad (**Age**), indica que hay viajeros de todas las edades en todas las clases, si asumimos, como hemos demostrado en apartados anteriores que el precio unitario es un indicador de la clase en la que viajaban los viajeros.<p>


<br>



**CARLOS: ENTIENDO QUE CAMBIARAS COSAS.MIRA QUE LOS COMENTARIOS CONCUERDEN SI CAMBIAS ALGO, PLEASE**

**2. --> Contrastes de hipótesis**


**Contraste de hipótesis sobre el sexo y nivel de supervivencia**

  
¿La proporción de supervivencia en hombres es inferior a la de las mujeres?  

  
Acorde con la pregunta planteada, realizaremos un contraste de hipótesis con las siguientes hipótesis de partida:  
  
**Hipótesis nula - H0**: La proporción de hombres que sobreviven es igual o mayor a 50% -> H0: p >= p0, siendo p0 = 0.5  
**Hipótesis alternativa - H1**: La proporción de hombres es menor a 50% -> H1: p < p0, siendo po = 0.5  
  
Este contraste de hipótesis representa un test de la proporción de la población por la cola izquierda, por tanto, el valor p0 representará, bajo la hipótesis nula, el límite inferior de la supuesta verdadera proporción de la población.  
Este contraste rechazará la HO si el estadístico calculado es menor o igual al valor crítico (con signo negativo) al nivel de significación estimado.  
  
El hecho que la proporción de hombres que sobreviven sea menor que 0.5, implicaría que la proporción de hombres que sobreviven es inferior a la de las mujeres.  
  
Debido a que es un contraste de hipótesis sobre proporción de una muestra, y esta muestra es considerada grande (n > 30), podremos definir un estadístico de contraste como una observación de una variable aleatoria que se distribuye aproximadamente como una N(0,1).  
  
Debido al planteamiento de la hipótesis nula y su alternativa y por cómo se han descrito las hipótesis H0 y H1, se observa que la hipótesis alternativa es unilateral, puesto que se plantea como un límite a un solo valor dado.  

  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Fijamos un nivel de significación

alfa <- 0.05
```

 
  
Determinamos el estadístico de contraste, en este caso, la muestra es grande y proviene de una distribución de Bernoulli de parámetro p, con lo cual, según el Teorema del Límite Central podremos utilizar el estadístico de contraste mostrado anteriormente.  
**OLGA: igual me equivoco, pero n_Sex_M/n_Sex es el número de hombres supervivientes frente al total de supervivientes. Yo creo que tiene que ser hombres supervivientes / hombres (supervivientes o no). Esto te da el porcentaje de hombres que sobrevivieron entre los hombres que viajaban. Lo que calculaste te da el porcentaje de hombres que sobrevivieron entre todos los pasajeros que sobrevivieron. Digamos viajaban 100 hombres y 900 mujeres y se salvaron todos los hombres y 300 mujeres. La proporción de hombres que sobrevivieron en este caso debería ser 100% porque todos sobrevivieron, y creo que con el cálculo que has hecho el porcentaje sería 25%. Ilustro con un plot y luego lo puedes quitar: n_Sex_M/length(train.male$Sex) son 19% y n_Sex_M/n_Sex son 31%. He dejado comentario en el código. Lo mismo con los demás contrastes.**

**CARLOS: OK**

  

```{r}
ggplot(data=train, aes(x=Sex, fill=as.factor(Survived)))+geom_bar(position = 'fill')
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Determinación del estadístico de contraste

train.survived_M <- train.survived[train.survived$Sex=="male",]
train.survived_F <- train.survived[train.survived$Sex=="female",]

n_Sex <- length(train.survived$Sex)

n_Sex_M <- length(train.survived_M$Sex)

n_Sex_F <- length(train.survived_F$Sex)

# Proporción muestral de hombres
p_hat <- n_Sex_M/n_Sex
# Olga reemplazar n_Sex por length(train.male$Sex)
# p_hat <- n_Sex_M/length(train.male$Sex)

# Proporción hipotesis nula
p_0 <- 0.5

# Estadístico empleado z_p
z_p = (p_hat - p_0)/sqrt(p_0 * (1 - p_0)/n_Sex) 

# Cálculo de valores críticos para el valor de significación asignado
z_p.alfa = qnorm(1-alfa) 

# Cálculo del valor P en nuestro contraste de hipótesis
valor_p_Sex = pnorm(z_p) 
 
kbl(data.frame(n_Sex,
           n_Sex_M,
           n_Sex_F,
           p_hat,
           p_0, z_p,
           -z_p.alfa,
           valor_p_Sex),booktabs =T)%>%
  kable_styling(latex_options =c("striped"))
```

  
<br>  



Tal y como se ha planteado H0 y H1, siendo H1 p < 0.5, rechazaremos H0 si el valor del estadístico z_p es menor que el valor crítico (en signo negativo), siendo este el caso -6.70 < -1.64.  

  
Según el estadístico de contraste utilizado y el valor crítico calculado, al ser el primero (**-6.70**) menor que el segundo (**-1.64**), al 0.05 de nivel de significancia, podemos rechazar la hipótesis nula de que la proporción de supervivencia en hombres es mayor o igual a 50% respecto al de las mujeres.  
  
De igual forma, al ser valor p casi nulo y por tanto menor que nuestro nivel de significación (0.05), el valor p es significativo y podemos rechazar, confirmando el contraste anterior, la hipótesis nula.  
  

Siguiendo la misma metodología, responderemos a las siguientes preguntas:


 <br> 
  
**¿La proporción de supervivencia en menores es inferior a la de los mayores?**  

<br>
  
**Hipótesis nula - H0**: La proporción de menores que sobreviven es igual o mayor a 50% -> H0: p >= p0, siendo po = 0.5  
**Hipótesis alternativa - H1**: La proporción de menores es menor a 50% -> H1: p < p0, siendo po = 0.5  
  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Determinación del estadístico de contraste

train.survived_Y <- train.survived[train.survived$Age<18,]
train.survived_O <- train.survived[train.survived$Age>=18,]

n_Age <- length(train.survived$Age)
n_Age_Y <- length(train.survived_Y$Age)
n_Age_O <- length(train.survived_O$Age)

# Proporción muestral de menores
p_hat <- n_Age_Y/n_Age

# Proporción hipotesis nula
p_0 <- 0.5

# Estadístico empleado z_p
z_p = (p_hat - p_0)/sqrt(p_0 * (1 - p_0)/n_Age) 

# Cálculo de valores críticos para el valor de significación asignado
z_p.alfa = qnorm(1-alfa) 

# Cálculo del valor P en nuestro contraste de hipótesis
valor_p_Age = pnorm(z_p) 




kbl(data.frame(n_Age,
           n_Age_Y,
           n_Age_O,
           p_hat,
           p_0,
           z_p,
           -z_p.alfa,
           valor_p_Age),booktabs =T)%>%
  kable_styling(latex_options =c("striped"))
```

  
<br>  



Según el estadístico de contraste utilizado y el valor crítico calculado, al ser el primero (**-10.92**) menor que el segundo (**-1.64**), al 0.05 de nivel de significancia, podemos rechazar la hipótesis nula de que la proporción de supervivencia en hombres es mayor o igual a 50% respecto al de las mujeres.  
  
De igual forma, al ser valor p casi nulo y por tanto menor que nuestro nivel de significación (0.05), el valor p es significativo y podemos rechazar, confirmando el contraste anterior, la hipótesis nula.  

<br> 
  

**¿La proporción de supervivencia en viajeros con billete único es inferior a la de los viajeros con billete en conjunto?**
  
<br>

**Hipótesis nula - H0**: La proporción de viajeros con billete único que sobreviven es igual o mayor a 50% -> H0: p >= p0, siendo po = 0.5  
**Hipótesis alternativa - H1**: La proporción de viajeros con billete único es menor a 50% -> H1: p < p0, siendo po = 0.5  

  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Determinación del estadístico de contraste

train.survived_S <- train.survived[train.survived$Count.ticket==1,]
train.survived_My <- train.survived[train.survived$Count.ticket>1,]

n_Count.ticket <- length(train.survived$Count.ticket)
n_Count.ticket_S <- length(train.survived_S$Count.ticket)
n_Count.ticket_My <- length(train.survived_My$Count.ticket)

# Proporción muestral de menores
p_hat <- n_Count.ticket_S/n_Count.ticket

# Proporción hipotesis nula
p_0 <- 0.5

# Estadístico empleado z_p
z_p = (p_hat - p_0)/sqrt(p_0 * (1 - p_0)/n_Count.ticket) 

# Cálculo de valores críticos para el valor de significación asignado
z_p.alfa = qnorm(1-alfa) 

# Cálculo del valor P en nuestro contraste de hipótesis
valor_p_Count.ticket = pnorm(z_p) 

kbl(data.frame(n_Count.ticket,
           n_Count.ticket_S,
           n_Count.ticket_My,
           p_hat,
           p_0,
           z_p,
           -z_p.alfa,
           valor_p_Count.ticket),booktabs =T)%>%
  kable_styling(latex_options =c("striped","scale_down"))
```

  
<br> 
 

Según el estadístico de contraste utilizado y el valor crítico calculado, al ser el primero (**-4.43**) menor que el segundo (**-1.64**), al 0.05 de nivel de significancia, podemos rechazar la hipótesis nula de que la proporción de supervivencia en hombres es mayor o igual a 50% respecto al de las mujeres.  
  
De igual forma, al ser valor p casi nulo y por tanto menor que nuestro nivel de significación (0.05), el valor p es significativo y podemos rechazar, confirmando el contraste anterior, la hipótesis nula.   

  
<br>

**3. --> Hipótesis sobre independencia de variables (Xi Cuadrado)**

**Relación entre supervivencia y billete único o grupal**
  
Utilizamos el test Chi cuadrado para comprobar si los pasajeros de primera clase sobrevivieron en mayor medida que los pasajeros de segunda clase.  
  
El test se aplica en R con un nivel de confianza por defecto del 95%.  
  
Crearemos dos tablas de contingencia entre las variables que indican supervencia y la que indica el tipo de billete. Una primera en valores absolutos, y una segunda mostrando las proporciones.
  


```{r echo=TRUE, message=FALSE, warning=FALSE}

# Tabla de contingencia Survived - Tipo Billete

table(train$Survived, train$ticket_tipo, dnn = c("Supervivencia", "Tipo Billete"))

# Tabla de contingencia en proporciones Survived - Tipo Billete
prop.table(table(train$Survived, train$ticket_tipo, dnn = c("Supervivencia (%)",
                                                            "Tipo Billete (%)")))

length(train$ticket_tipo)
length(train$Survived)

```
  
  
<br>


Dos variables categóricas que forman parte de una tabla de contingencia pueden ser sujetas a un test de independencia. Este test puede ser representado for el ChiSquare Test mediante un contraste de hipótesis.  
  
El contraste se realizará para observar si las dos variables son independientes o no, por tanto, podemos plantear las hipótesis como se indica a continuación:  

<br>
  
**Hipótesis nula - H0**: Las variables Survived y Tipo Billete son independientes.  
**Hipótesis alternativa - H1**: Las variables Survived y Tipo Billete están relacionadas.  

  

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Tabla de contingencia Survived y Tipo Billete
tabla_cont <- table(train$Survived, train$ticket_tipo, dnn = c("Supervivencia",
                                                               "Tipo Billete"))
tabla_cont

# Comprobación con la función chisq.test()
chisq.test(tabla_cont)
```
  
  
<br>

El cálculo de los grados de libertad para una distribución Chi Square se calcula como df = (c - 1)(r - 1) donde c es el número de columnas y r el número de filas. En nuestro caso c = r = 2, por lo tanto df = (2 - 1)(2 - 1) = 1.

<br>

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Grados de libertad
gdl <- 1

# Nivel de confianza
ndc <- 0.95


# Valor Crítico
val_cri <- qchisq(ndc, gdl)
val_cri

```
  
  
<br>


Debido a que el estadístico Chi Square es mayor al valor crítico calculado de la distribución Chi Square (con un grado de libertad y con un nivel de significación de 0.05), podemos rechazar la hipótesis nula de que no hay relación entre Survived y Tipo de Billete, es decir, rechazamos la hipótesis al 95 % de nivel de confianza de que tales variables sean independientes.  
  
Como el valor de p-value es menor que el nivel de significancia, **podemos rechazar la hipótesis nula de que las variables Survived y Tipo de Billete son independientes**, cuadrando este resultado con los cálculos anteriores.
  
Por tanto, se puede afirmar al 95% de nivel de confianza que las variables Survived y Tipo de Billete **están relacionadas**.

<br> 
  
**Relación entre supervivencia y la clase en la que viajaban los pasajeros**  

<br>

Planteamos las hipótesis nula y alternativa:   

**Hipótesis nula - H0** : Las variables Survived y Pclass son independientes.  
**Hipótesis alternativa - H1**: Las variables Survived y Pclass están relacionadas.  

Igual que hicimos en el ejemplo anterior, calculamos la tabla de contingencia. 

```{r}
# Tabla de contingencia
tabla_cont1 <- table(train$survived, train$Pclass, dnn = c("Supervivencia", "Clase"))
tabla_cont1
```


```{r}
prop.table(table(train$survived, train$Pclass, dnn = c("Supervivencia (%)", "Clase (%)" )))
```
```{r}
chisq.test(tabla_cont1)
```
```{r}
# Grados de libertad
gdl1 <- 1  

# Nivel de confianza
ndc1 <- 0.95

# Valor crítico
val_cri1 <- qchisq(ndc1, gdl1)
val_cri1
```

<br>

Los resultados que hemos obtenido son:<p>


* El valor p-value es mucho menor que el nivel de significancia.  
* El valor crítico es menor que el estadístico observado.  

Con estos datos podemos concluir **que podemos rechazar H0 a favor de H1 con un nivel de confianza del 95%**, dados el valor p-value y el valor crítico.  



**CARLOS: QUIERES INCLUIR EL T TEST CON EL RESTO DE CONTRASTES JUNTO CON EL OTRO CONTRASTE DE EDAD O LO BORRAMOS?**


<br>

**Contraste de hipótesis sobre la edad de supervivencia**
  
Planteamos la pregunta de investigación: Queremos saber si las personas que sobrevivieron eran más jóvenes que las personas que murieron en el accidente o, por el contrario, la edad para las personas que muerieron y sobrevivieron es similar.   
  
Nos encontramos ante el caso en el que podemos asumir la normalidad de las distribuciones de la media de las dos muestras pero sabemos que las varianzas de las muestras son iguales Se trata de un test paramétrico de dos muestras. 

  
H0: La media de edad de las personas supervivientes es la misma que de las personas que muerieron  
H1: La media de edad de las personas que murieron es mayor que la de las personas supervivientes.    
  
Usamos un test paramétrico definido por `t.test`
  

Con un valor p-value por debajo de 0.05 podemos aceptar la hipótesis H1. Con un nivel de confianza del 95% afirmamos que las personas que murieron en el Titanic tienen una media de edad más alta que las personas que sobrevivieron.  

  

```{r echo=TRUE, message=FALSE, warning=FALSE}
t.test(train.not.survived$Age, train.survived$Age, alternative="greater", var.equal=TRUE)
```
  
 
  



<br>

  
  
**4. --> Regresión Logística**   

<br> 

**Primera Regresión Logística**

<br>

Aplicamos una regresión logística para predecir la probabilidad de supervivencia usando como variable predictora la variable **sexo**.  
  
Según los datos que nos proporciona la función `summary` la variable sexo **es significativa para predecir la supervivencia**. El coeficiente negativo asociado a la variable dummy **Sexmale** indica que ser de sexo masculino reduce la probabilidad de sobrevivir.<p>

<br>

  
```{r echo=TRUE, message=FALSE, warning=FALSE}
model0=glm(formula=trainy~Sex, data=regr.data, family=binomial(link=logit))

summary(model0)

```

<br>

**CARLOS: NO ENTIENDO QUE QUIERE DECIR "PROTEGIDOS".. :(**

Calculamos los Odds Ratio. Los odds ratio indican que ser hombre es factor de protección para la clase 1 (sobrevivir). Los hombres están "protegidos" de la supervivencia en comparación con las mujeres.  

<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
exp(coefficients(model0))

```
  
<br>

**CARLOS:SUPONGO QUE 75 y 157 SON NUMEROS QUE SALES RANDOMLY.. HABRIA QUE VERIFICAR EL ULTIMO MODELO PROCESADO Y QUE CUADREN LOS NUMEROS**

Usamos los datos de validación para realizar una predicción de supervivencia.<p>

Tenemos que 75 instancias de supervivencia y 157 instancias de no supervivencia han sido predichas correctamente.<p>
39 instancias de supervivencia real han sido predichas como no supervivencia<p>
26 instancias de no supervivencia fueron predichas incorrectamente como supervivencia.<p>

<br>
  
  **CARLOS: NO OLVIDARSE DE ACTUALIZAR LA PRECISION XXXXXXXX CON LA ULTIMA QUE NOS DE**
  
El modelo de regresión que utiliza únicamente la variable Sexo para predecir la supervivencia tiene una **precisión del XXXXXXX%**.  
  
```{r}
newdata0 <- validX[c("Sex")]
probabilities <- model0 %>% predict(newdata0, type = "response")

predicted.classes <- ifelse(probabilities > 0.5, 1, 0)

# Matriz de confusión
conf.1 <- table(validy, predicted.classes)
conf.1

# Precisión
sum(diag(conf.1))/sum(colSums(conf.1))

```

  
<br>


**Segunda Regresión Logística**

<br>


Aplicamos una regresión logística para comprobar si las variables **Sexo** y **Clase** son significativas para la supervivencia en el accidente.  
  
Ambas variables son significativas y así lo indican los asteriscos junto a los valores Pr(>|z|).  
  
**Ser hombre, viajar en clase 2 o clase 3 reduce la posibilidad de supervivencia con respecto a ser mujer y viajar en primera clase.**<p>

Esto viene indicado por el signo negativo que acompaña el valor del coeficiente para Sexmale, Pclass2 y Pclass3.   
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Modelo de regresión
model1=glm(formula=trainy~Sex+as.factor(Pclass), data=regr.data,
           family=binomial(link=logit))

summary(model1)

```


<br>

Calculamos los odds ratio. Igual que en el caso anterior vemos que **la probabilidad ser hombre y sobrevivir es mucho menor que la de ser mujer y sobrevivir**.<p>

Por clases el OR indica que **estar en segunda o tercera clase es factor de protección** (pocas probable sobrevivir) respecto a la primera clase.  

<br>
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
exp(coefficients(model1))
```
  
  
<br>


**CARLOS: TIENE QUE DAR IGUAL PRECISION?**

Realizamos la predicción sobre el conjunto de validación que obtuvimos y con el resultado creamos una matriz de confusión y calculamos la precisión. El resultado es igual que en la regresión anterior.  

  
```{r}
newdata1 <- validX[c("Sex","Pclass")]
probabilities1 <- model1 %>% predict(newdata=newdata1, type = "response")
predicted.classes1 <- ifelse(probabilities1 > 0.5, 1, 0)
# Matriz de confusión
conf.2 <- table(validy, predicted.classes1)
conf.2

# Precisión
sum(diag(conf.2)) / sum(colSums(conf.2))

```

  
<br>  

**Tercera Regresión Logística**

<br>


Por último generamos un modelo que incluye todas las variables disponibles.<p>
  
En los datos hemos detectado que había hasta 8 pasajeros con el mismo billete. Posiblemente se tratara de familia o amigos. Usaremos esta variable para crear un modelo.  

<br>

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Modelo de regresión
model2=glm(formula=trainy~factor(Pclass)+Sex+Age+factor(Count.ticket)+Embarked,data=regr.data, family=binomial(link=logit))

summary(model2)


```


<br>  


**CARLOS: SEGUN RESULTADOS TAMBIEN EL COEFICIENTE ES POSITIVO PARA 2 PERSONAS? A LO MEJOR ESTOY MEZCLANDO COSAS....**

El resultado del modelo indica que **cuando  tres o cuatro personas viajaban juntas, la probabilidad de sobrevivir aumentaba** (signo positivo del coeficiente).  
  
Calculamos los ORS. Para las personas que viajaban con otra persona, otras dos o tres personas el "riesgo" de sobrevivir es mucho mayor.   

<br>
 
```{r echo=TRUE, message=FALSE, warning=FALSE}

exp(coefficients(model2))
```

  
  

```{r}
newdata2 <- validX[c("Pclass", "Sex", "Age", "Count.ticket", "Embarked")]
probabilities2 <- model2 %>% predict(newdata2, type = "response")

predicted.classes2 <- ifelse(probabilities2 > 0.5, 1, 0)
# Matriz de confusión
conf.3 <- table(validy, predicted.classes2)
conf.3

# Precisión

sum(diag(conf.3)) / sum(colSums(conf.3))


```

<br>
  

**5. --> Árboles de decisión CART**  

<br> 

En primer lugar creamos un árbol de decisión para predecir la supervivencia de los pasajeros del Titanic tomando en cuenta las variables explicativas del conjunto de entrenamiento y la etiqueta de clase (Supervivencia o no).<p>   
  

Usamos los datos del conjunto train para entrenar el modelo y visualizamos el árbol y los datos del modelo.  
  
```{r}
treeFit <- rpart(trainy~.,data=trainX,method ='class')
print(treeFit)
```
  
  
**OLGA:** las conclusiones no están bien, se ha generado otro árbol. Voy a revisar esto lo último

**CARLOS: OK!**

*El árbol ha realizado las particiones de los datos en base a la variable Sex. Los pasajeros de sexo masculino, mayores de 13 años tienen como clase por defecto la no supervivencia. Los pasajeros que pagaron entre 26 y 32 dólares y menores de 52 años no sobreviven. Los pasajeros menores de 14 años si viajaban con menos de 3 hermanos casi todos sobreviven.*  
  
*Por otra parte, los pasajeros de sexo Femenino en que viajaban en tercera clase sobrevivieron si viajaban con menos de 5 personas (count ticket), si pagaron menos de 8.1 dólares y si tenían edad menor de 28 años. Todos los demás se clasifican como no supervivientes. Las mujeres en otras clases distintas de la tercera sobrevivieron en su mayoría.*    
  
*En el árbol podemos ver que se ha considerado variables bastante diferentes para clasificar a los hombres y a las mujeres. Para los hombres la edad ha sido un factor importante para la supervivencia, principalmente sobrevivieron los hombres menores de 14 años. En el caso de las mujeres el factor determinante ha sido la clase y las personas con las que viajaban.*  
  

```{r}
# Árbol resultante.  
rpart.plot(treeFit)
```
  
<br>  

Predecimos usando los datos de validación.  

<br>
```{r}
prediction <- ifelse(predict(treeFit,newdata=validX)[,1] > predict(treeFit,newdata=validX)[,2], 0, 1)

```


<br>
  
Con la matriz de confusión y el valor de Accuracy podemos ver que la predicción ha mejorado con respecto a la regresión logística.  

<br>  

```{r}
confusionMatrix(as.factor(prediction), validy)

```

<br>  
  


**Árbol de decisión usando cross validation y búsqueda de mejor parámetro**   
  
Podemos entrenar un árbol de decisión usando cross validation y la búsqueda en rejilla.  
  
Cross validation consiste en dividir los datos en partes (parámetro number) y ejecutar el modelo varias veces usando como test set una de las particiones de los datos. El mejor modelo es aquel que tiene la mejor métrica y en nuestro caso la métrica a considerar es "Accuracy".  
  
Con la búsqueda en rejilla podemos especificar al modelo una lista de valores para uno o más parámetros. Especificamos **cp**, el parámetro de compejidad que se define como mejora mínima de pureza que es necesaria en cada nodo. cp es un criterio de parada, así el árbol para de hacer particiones cuando la mejora no supera el valor pasado al parámetro cp.  
  
Una combinación de trainControl y expand.grid da lugar al boosting, una búsqueda de parámetros óptima en conjunto con validación cruzada.  
  
```{r}

control <-  trainControl(method="repeatedcv",
                         number=3,
                         repeats=3,
                         savePredictions = TRUE)
metric <- "Accuracy"
grid <- expand.grid(cp = seq(0.0001,0.05,0.001))
# Entrenando el modelo.
model.boost <- train(y=as.factor(trainy),
                     tuneGrid=grid,x=trainX,
                     method="rpart",
                     metric=metric,
                     trControl=control)

# Resumen de resultados
print(model.boost)


```

  
<br> 

Haremos la validación cruzada o crossvalidation con **10 folds** y busqueda de los mejores parámetros usando el expand.grid. Utilizaremos la métrica Accuracy que mide el porcentaje de instancias correctas sobre total.  Entrenamos el modelo con los datos trainX y trainy, establecemos el método que es el mismo que aplicamos en el primer árbol de decisión de esta práctica (rpart) como parámetro de la función.  

<br>  

```{r}
model.boost$finalModel
prediction <- ifelse(predict(model.boost$finalModel,
                             newdata=validX)[,1]>0.50, "0", "1")

table(prediction, validy)


```
  
  

```{r}
rpart.plot(model.boost$finalModel, box.col=c("red", "green"))
```

  
  

```{r}
model.boost$levels
```

  


```{r}
plot(model.boost)
```

<br> 
  
Visualizamos las iteraciones de boosting vs la precisión. **Tenemos la mayor precisión con 25 iteraciones**.  

<br>  

```{r echo=TRUE, message=FALSE, warning=FALSE}
predicted_model.boost <- predict(model.boost, newdata=validX)
cmat <- confusionMatrix(predicted_model.boost, as.factor(validy))
cmat
```

  
  

**CARLOS: QUIERES MOSTRAR LOS RESULTADOS DE PREDICTORS?**

```{r}
# Definición del control de entrenamiento para los multiples modelos
fitControl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3,
savePredictions = 'final',
classProbs = T)

# Definiendo predictores y resultados
predictors<-colnames(trainX)

```

<br>

**6. --> Random Forest**  

<br> 
  
```{r}
# Entrenando el modelo de Random Forest
#model_rf<-train(trainX,y=as.factor(trainy.1),method='rf',trControl=fitControl,tuneLength=9)

# Prediciendo con el modelo Random Forest
#validX$pred_rf<-predict(object = model_rf,validX)

# Chequeo de la precisión del modelo Random Forest
#confusionMatrix(as.factor(validy.1),validX$pred_rf)
```




```{r}
#plot(model_rf)
```




## **Including Plots**

  
  


******
# **Representación de resultados**
******
  
  



## **Tabla resumen de las variables cualitativas (datos completos: train + test)**

  
Realizaremos una tabla resumen con las frecuencias relativas y las frecuencias absolutas de las variables cualitativas.
Creamos un dataframe auxiliar para generar nuestra tabla.

  
Calculamos, para todos los campos, la frecuencia relativa y absoluta a través del contaje dividido por el número total de filas del dataframe.
  
Creamos una tabla mediante la función kable().

  

```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=60)}

col_var_cualitativa_sin_ID <- c("Pclass", "Sex", "Embarked")

df_var_cualitativa <- df_total_sin_etiqueta[, col_var_cualitativa_sin_ID]

df_var_cualitativa$Sex <- as.factor(df_var_cualitativa$Sex)
df_var_cualitativa$Embarked <- as.factor(df_var_cualitativa$Embarked)


# Frecuencias relativas y absolutas de campo PClass
Pclass_table_frec <- (count(df_var_cualitativa$Pclass))
Pclass_table_cum <- (count(df_var_cualitativa$Pclass)/dim(df_var_cualitativa)[1])[2]

Pclass_table <- cbind (Pclass_table_frec, Pclass_table_cum)

# Frecuencias relativas y absolutas de campo Sex
Sex_table_frec <- (count(df_var_cualitativa$Sex))
Sex_table_cum <- (count(df_var_cualitativa$Sex)/dim(df_var_cualitativa)[1])[2]

Sex_table <- cbind (Sex_table_frec, Sex_table_cum)

# Frecuencias relativas y absolutas de campo Embarked
Embarked_table_frec <- (count(df_var_cualitativa$Embarked))
Embarked_table_cum <- (count(df_var_cualitativa$Embarked)/dim(df_var_cualitativa)[1])[2]

Embarked_table <- cbind (Embarked_table_frec, Embarked_table_cum)



# Unión de toda la tabla asignando el nombre de las columnas
df_var_cualitativa_table <- rbind.data.frame(Pclass_table, Sex_table, Embarked_table)
colnames(df_var_cualitativa_table) <- c("Variable Cualitativa",
                                        "Frecuencia Absoluta",
                                        "Frecuencia Relativa")

# Variables auxiliares para la creación de la tabla kable() de forma más automática.

# Dimensiones de cada grupo de la tabla
dim_grupo1_ = length(unique(df_var_cualitativa$Pclass))
dim_grupo2_ = length(unique(df_var_cualitativa$Sex))
dim_grupo3_ = length(unique(df_var_cualitativa$Embarked))



# Límites de las posiciones de los grupos (automatico)
dim1_i <- 1
dim1_f <- dim_grupo1_
dim2_i <- dim1_f +1
dim2_f <- dim_grupo1_ + dim_grupo2_
dim3_i <- dim2_f +1
dim3_f <- dim_grupo1_ + dim_grupo2_ + dim_grupo3_



# Formato de la tabla mediante función kable()
# Formato de los dígitos de los campos
# Creación del título de la tabla y anotación
kable(df_var_cualitativa_table, digits = c(0,0,3),
  caption = "-TABLA RESUMEN DE LAS VARIABLES CUALITATIVAS-
      <p> (Total observaciones: 1309. Suma de frecuencias relativas sin redondeo = 1.000)") %>%
  kable_styling("striped",
                full_width = F) %>%
  pack_rows("Clases Embarque",
            dim1_i,
            dim1_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Sexo",
            dim2_i,
            dim2_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Embarque",
            dim3_i,
            dim3_f,
            label_row_css = "background-color: #666; color: #fff;")

```

  
  





## **Tabla resumen de las variables cuantitativas (datos completos: train + test)**

  
Realizaremos una tabla resumen con los **estadísticos principales de tendencia central y dispersión**, con **medidas robustas y no robustas**.
Para ello, utilizaremos tres funciones que nos aportarán diferentes estadísticos a utilizar:


* describe()<p>
* winsor.mean() (aplicaremos unos límites del 5 %)<p>
* stat.desc()<p>

<br>

Estas tres funciones nos darán diversos estadísticos que uniremos y ordenaremos en una única tabla para mostrar un completo resumen estadístico de las variables cuantitativas.

  
Finalmente, creamos una tabla mediante la función kable().


```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

# Creación tabla con describe()
col_var_cuantitativa_sin_ID <- c("Age", "SibSp", "Parch", "Count.ticket", "Unit.price")

df_var_cuantitativa <- df_total_sin_etiqueta[, col_var_cuantitativa_sin_ID]

df_var_cuantitativa_tabla <- describe(df_var_cuantitativa, quant = TRUE, IQR = TRUE)

# Creación tabla con winsor.mean()
winsor <- data.frame(t(winsor.mean(df_var_cuantitativa, trim= 0.05)))
winsor_df <- data.frame(t(winsor))
colnames(winsor_df) <- c("Winsor Mean 5%")

# Unión tablas describe() con winsor.mean()
df_var_cuantitativa_tabla$Winsor_Mean_.5 <- winsor_df$`Winsor Mean 5%`

# Eliminación campos no usables
df_var_cuantitativa_tabla <- df_var_cuantitativa_tabla[, -c(1, 11, 12, 15 )]

# Cambio de nombres de los campos
colnames(df_var_cuantitativa_tabla) <- c("Number", "Mean", "St_Dev",
                                         "Median", "Trimmed_Median", "MAD",
                                         "Min", "Max", "Range", "SE_Mean",
                                         "IQR", "Winsor_Mean_0.5")




```
  
  

```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

options(digits=2)

# Creación tabla con stat.desc()
df_var_cuantitativa_tabla2 <- as.data.frame(t(round(stat.desc(df_var_cuantitativa),2)))

# Cambio de nombres de los campos
colnames(df_var_cuantitativa_tabla2) <- c("tot_num", "NUll", "NA", "Min_", "Max_",
                                          "Range_", "sum", "median_", "mean_",
                                          "se_mean_", "CI_Mean_0.95", "Var",
                                          "stddev_", "Coef_Var")

# Eliminación campos no usables
df_var_cuantitativa_tabla2 <- df_var_cuantitativa_tabla2[, -c(1, 2, 4, 5, 6 ,7,
                                                              8, 9, 10, 13)]



```

  
  

```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

# Unión tablas describe()/winsor.mean() con tabla stat.desc()
counterdf_cuan <- c(1:dim(df_var_cuantitativa_tabla2)[2])
df_var_cuantitativa_tabla_dim_ini <- dim(df_var_cuantitativa_tabla)[2]

for (i in counterdf_cuan){
      df_var_cuantitativa_tabla[i+df_var_cuantitativa_tabla_dim_ini] <- df_var_cuantitativa_tabla2[i]
     }

# Reordenamiento de las columnas para poder agrupar los campos por temática:
# tendencia central, dispersión, robusta y no robusta
df_var_cuantitativa_tabla <- df_var_cuantitativa_tabla[, c(2, 10, 14, 4, 5, 12,15, 16,
                                                           3, 6, 11, 1,13, 7, 8, 9)]


# Creación del dataframe haciendo la transpuesta de la tabla anterior para tener 
# los estadisticos en las fila y las variables en las columnas.
df_var_cuantitativa_tabla <- data.frame(t(df_var_cuantitativa_tabla))



```

  
  






```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

# Creación de la tabla mediante kable()

# Formato numérico no científico
options(scipen = 999)

# Variables auxiliares para crear de la tabla kable() de forma más automática.
# Dimensiones de cada grupo de la tabla
dim_grupo1 = 3
dim_grupo2 = 3
dim_grupo3 = 3
dim_grupo4 = 2
dim_grupo5 = 5

# Límites de las posiciones de los grupos (automatico)
dim1_i <- 1
dim1_f <- dim_grupo1
dim2_i <- dim1_f +1
dim2_f <- dim_grupo1 + dim_grupo2
dim3_i <- dim2_f +1
dim3_f <- dim_grupo1 + dim_grupo2 + dim_grupo3
dim4_i <- dim3_f +1
dim4_f <- dim_grupo1 + dim_grupo2 + dim_grupo3 + dim_grupo4
dim5_i <- dim4_f +1
dim5_f <- dim_grupo1 + dim_grupo2 + dim_grupo3 + dim_grupo4 + dim_grupo5

# Formato de la tabla mediante función kable()
# Formato de los dígitos de los campos
# Creación del título de la tabla y anotación
kable(df_var_cuantitativa_tabla,digits = c(2, 2, 2, 3),
      caption = "-TABLA RESUMEN DE LAS VARIABLES CUANTITATIVAS-
      <p> (Total observaciones: 1309.)") %>%
  kable_styling("striped",  full_width = F) %>%
  pack_rows("Tendencia Central (medidas  NO robustas)",
            dim1_i,
            dim1_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Tendencia Central (medidas robustas)",
            dim2_i,
            dim2_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Dispersion (medidas NO robustas)",
            dim3_i,
            dim3_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Dispersion (medidas robustas)",
            dim4_i,
            dim4_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Información Adicional", dim5_i, dim5_f,
            label_row_css = "background-color: #666; color: #fff;")





```

  
  





  
  
******
# **Resolución del problema**
******  

  
  
Al inicio de las práctica nos planteamos descubrir los posibles factores que pudieron influir en la supervivencia o no supervivencia de los pasajeros del Titanic.<p>

<br>

Para poder responder a esta pregunta, hemos realizado una serie de pasos:

* Carga de los datos<p>
* Integración de los datos<p>
* Creación de nuevas variables y eliminación de variables innecesarias<p>
* Imputación de valores nulos y tratamiento de outliers.<p>

<br>

Hemos usamos los datos procesados para realizar una exploración visual de los datos, aplicar técnicas de estadística inferencial y modelos de aprendizaje automático.  

Las variables con las que trabajamos en nuestro dataset procesado, además de la variable dependiente *Survived** han sido:<p>

* Pclass<p>
* Sex<p>
* Age<p>
* SibSp<p>
* Parch<p>
* Embarked<p>
* Count.ticket<p>
* Unit.price, y<p>
* Ticket_tipo<p>

siendo las últimas 3 variables calculadas. 


<br>



**Conclusiones extraídas del análisis visual:** 

- Las personas que sobrevivieron eran algo más jóvenes (mediana), y pagaron más por sus billetes.  

<br>

- La proporción de personas de primera clase que sobrevivió al accidente es mayor que la proporción de supervivientes en tercera y incluso en segunda clase.<p>

<br>

- De los supervivientes en el accidente la mayoría de personas eran mujeres.<p>

<br>

- En tercera clase la mitad de las mujeres no sobrevivieron.<p>

<br>

- La proporción de mujeres supervivientes en primera y segunda clases es muy alta.<p>

<br>

- En cuanto a la supervivencia de los hombres, los hombres de primera clase sobrevivieron en mayor proporción que los hombres de otras clases, sin embargo, la proporción de hombres supervivientes de tercera clase es menor que la de mujeres supervivientes de tercera clase.<p>



```{r}
ggplot(data=train, aes(x=Sex, fill=Survived))+
  geom_bar(position = 'fill')+
  facet_wrap(~Pclass)+
  scale_fill_manual(values=c("black", "orange"))
```

Otro factor que nos ha parecido interesante es la compañía de los pasajeros en el crucero. La mayoría de los pasajeros viajaron solos, sin embargo, **había muchos billetes que tenían el mismo número para pasajeros distintos**.<p>

Este número está relacionado con las variables Parch y SibSp, pero no indica el parentesco. Según las visualizaciones que realizamos, **las personas que viajaban con acompañantes sobrevivieron en mayor proporción que las personas que viajaban solas**.  

```{r}

plot(table(train$Count.ticket, train$Survived),
     col = c("black", "orange"), main="Embarked")
```

<br>

**Conclusiones del análisis inferencial:** 

En el análisis inferencial hemos realizado varios contrastes de hipótesis para confirmar o desmentir las conclusiones que obtuvimos durante el análisis visual de los datos.

<br>

Con el contraste sobre el sexo y el nivel de supervivencia hemos podido afirmar con un nivel de confianza del 95% que **la proporción de hombres que sobrevivieron al accidente era menor que la proporción de mujeres que sobrevivieron**. Asimismo **la proporción de menores de edad supervivientes es mayor que la de mayores de edad supervivientes**. 


**Conclusiones de regresión logística**:  

En las regresiones que hemos aplicado las principales conclusiones extraidas han sido que las variables **Sex**, **Pclass**, **Age** son significativa para predecir la supervivencia de los pasajeros del Titanic.<p>

<br>

A partir de los coeficientes negativos en Pclass 2, Pclass3 y Sexmale deducimos que **las personas en segunda y tercera clase y los hombres tenían menos posibilidades de sobrevivir que las mujeres**.

<br>

La variable dummy **Count.ticket 6** también es significativa para el modelo final y su coeficiente indica que **para grupos de 6 viajeros las posibilidades de sobrevivir se reducían**.  


**CARLOS: TAL COMO COMENTAS CREO QUE QUIERES REVISAR EL MODELO PRIMERO ANTES DE LA CONCLUSIONES**

**Conclusiones árbol de decisión:**  

Tras aplicar el árbol de decisión obtuvimos una mejor visión de los posibles motivos de supervivencia.<p>

Para los hombres la supervivencia por defecto es 0 (no supervivencia), a no ser que sean menores de 13 años.<p>

En el caso de las mujeres el factor determinante ha sido **la clase en la que viajaban**. La mayoría de mujeres que viajaban en primera y segunda clase sobrevivieron. De las mujeres que viajaban en tercera clase sobrevivieron las menores de 28 años, que viajaban con 4 o menos acompañantes.  


**CONCLUSIONES FINALES**.  

Tras realizar una inspección visual, aplicar métodos de estadística inferencial, regresiones y árboles de decisión podemos ver que entre todos los métodos hay consenso en cuanto a los factores que influyeron en la supervivencia o no de los pasajeros del Titanic.<p>


* El sexo de las personas que viajaban tuvo mucha influencia en su supervivencia:<p>

- En caso de los hombres, la supervivencia era mayor para niños.<p>
- En el caso de las mujeres, no fue tan importante la edad como la clase en la que viajaban. Las mujeres de primera y segunda clase sobrevivieron en su mayoría.  

* Las personas que viajaban con uno o más acompañantes también sobrevivieron en mayor proporción.  






******
# **Creación del archivo preprocesado**
******
  
  
  
  


******
# **Tabla de Contribuciones a la Práctica**
******
  
<br>

**CARLOS: ELIGE EL FORMATO DE TABLA QUE QUIERAS. PONGO LAS INICIALES DE LOS NOMBRES SEGUN ENUNCIADO PRACTICA**

```{r}
cont <- data.frame(rbind(c("Investigación Previa", "Olga Garcés / Carlos Acosta"),
                         c("Redacción de las respuestas", "Olga Garcés / Carlos Acosta"),
                         c("Desarrollo código", "Olga Garcés / Carlos Acosta")))
colnames(cont) <- c("Contribuciones", "Firma")

kbl(cont)
```


<br>

Contribuciones | Firma
------------------- | ----------------- 
Investigación Previa|O. G. / C. A.
Redacción de las respuestas|O. G. / C. A.
Desarrollo código|O. G. / C. A.

<br>



