---
title: "**M2.851 – TIPOLOGÍA Y CICLO DE VIDA DE LOS DATOS: PRA 2**"
author: "Olga Garcés Ciemerozum / Carlos Acosta Quintas"
date: 'Junio 2021'
  
output:
  pdf_document:
    highlight: zenburn
    toc: yes
     
  word_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 4
---

<style>
body {
text-align: justify}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
options(width = 500)

```

<br><br><br>


```{r load_libraries, message=FALSE, warning=FALSE, include=FALSE}
# Cargamos las librerias de  R que vamos a usar
library("ISLR")
library("SmartEDA")
library("tidyverse")
library(DT) # Para visualizar tablas
library(VIM)
library(readr)
library(plyr)
library (MASS)
library(grid)
library(ggpubr) # Para QQ plot
library(ggplot2) # Para graficos
# library(stringr) #Para str_to_title()
# library(reshape) #Para Pivot Tables
# library(VIM) # Para kNN
library(psych) # Para Grafico Correlaciones
library(pastecs) #Para tabla resumen cuantitativa
library(gmodels) #Para tabla resumen cualiativa
library(knitr) #Para Kable
library(kableExtra) #Para Kable
library(hrbrthemes) #Para gráficos densidades
library(dplyr) #Para gráficos densidades
library(vioplot) #Para gráficos violin
library(PASWR) #Estadístico z
library(BSDA) #Estadístico z.test
library(lsr) #Eta2
library(faraway) #Multicolinealidad
library(gridExtra) #Grid graficas
library(corrplot) #Plot para correlaciones
library(ResourceSelection) #Hosmer Lemeshowi
library(InformationValue) #ROC
library(plotROC)#ROC
library(DescTools) #Scheffe test
```

<br><br><br>




Introducción



El presente informe forma parte de la segunda práctica de la asignatura M2.851 - Tipología y ciclo de vida de los datos del Máster Universitario en Ciencia de Datos impartido por la Universitat Oberta de Catalunya.

En esta práctica se realizarán técnicas de limpieza de datos aplicadas a un juego de datos determinado y también se analizarán dichos datos para extraer información relevante y útil.

A su vez, se entregará, junto con la presente memoria, una serie de archivos con el código necesario para la realización de la limpieza y análisis con el que el usuario podrá realizar diferentes estudios analíticos a posteriori si lo desease.




******
# **Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?**
******

## **Descripción del dataset**



El dataset Titanic reune los datos sobre los pasajeros que viajaban a bordo del Titanic y registra para cada persona su supervivencia o no en el accidente. El Titanic transportaba a pasajeros con gran diversidad en sus niveles de renta y edad y a bordo se encontraban familias enteras.


La etiqueta (variable a predecir) es la variable dicotómica que indica si el viajero ha sobrevivido o no.


La ubicación en kaggle del dataset utilizado se muestra en el siguiente link:

https://www.kaggle.com/c/titanic/data

Los archivos disponibles son 3 y están en formato csv. Sus nombres son:

•	train.csv  
•	test.csv  
•	gender_submission.csv: Ejemplo a seguir en la entrega de la competición Kaggle (no útil).  


Según los registros, en el Titanic viajaban 2229 personas, de las cuales 913 formaban parte de la tripulación del barco. El dataset que obtenemos de Kaggle tiene un total de 1309 registros, por lo tanto, no todos los pasajeros que viajaban a bordo están incluidos en el dataset y podemos asumir que el juego de datos es una muestra de toda la población a analizar.

El dataset original está compuesto por dos ficheros: el fichero pensado para realizar el entrenamiento de un modelo (train.csv) y el fichero con los datos destinados a testear la calidad del modelo (test.csv). El fichero de entrenamiento contiene una columna más que el fichero de prueba. Esta columna corresponde a la columna de la clase "Survived".   

El fichero de entrenamiento tiene 891 registros mientras que el fichero de test contiene 418 instancias.  



Las variables de las que se compone el dataset son y sus unidades o magnitudes de las características son: 

**PassengerId**:  
Identificador del pasajero  
Tipo: Entero indicando un identificador único de casa instancia.  

<p>

**Survived**:  
Indica si el pasajero ha sobrevivido la catástrofe  
Tipo: Entero (categórica) 0 = No ha sobrevivido; 1 = Ha sobrevivido  

<p>

**Pclass**:  
Clase en la que viajaba el pasajero  
Tipo: String (categórica) 1 = 1 a clase; 2 = 2 a clase; 3 = 3a clase  

<p>

**Name**:  
Nombre del pasajero  
Tipo: String  

<p>

**Sex**:  
Sexo del pasajero  
Tipo: String (categórica) female = Mujer; male = hombre  

<p>

**Age**:  
Edad del pasajero  
Tipo: Entero  

<p>

**SibSp**:  
Indica si el pasajero tenía hermanos o pareja a bordo  
Tipo: Entero  

<p>

**Parch**:  
Indica si el pasajero tenía padres o hijos a bordo  
Tipo: Entero  

<p>
        
**Ticket**:  
Número del billete  
Tipo: String alfanumérico  

<p>
 
**Fare**:  
Precio del billete sin especificar si es un billete individual o grupal  
Tipo: Número Real  


**Cabin**:  
Número de camarote  
Tipo: String  

<p>
        
**Embarked**:  
Indica si el pasajero ha embarcado o no y donde  
Tipo: String (categórica) C = Cherbourg, Q = Queenstown, S = Southampton  

       
Los datos no han pasado por un proceso de preprocesado o limpieza, por lo que aún pueden existir inconsistencias y el formato no es necesariamente el más adecuado para un análisis directo.

**Carga del dataset**:

Cargamos el dataset y mostramos sus dimensiones, estructura y tipo de datos:



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Carga de los archivos que contienen los datos del train y test
test <- read.csv("titanic/test.csv")
train <- read.csv("titanic/train.csv")

train_rows <- dim(train)
test_rows <- dim(test)

train_rows
test_rows
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estructura de los archivos train.csv y test.csv
str(train)
str(test)
```


Visualizamos las primeras líneas del conjunto de entrenamiento y de test.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Primeras líneas del conjunto de entrenamiento y de test.
head(train)
head(test)
```

## **¿Por qué es importante el dataset?**


Este dataset es importante porque nos permite esclarecer qué factores pudieron influir en la supervivencia de viajeros del Titanic y obtener el conocimiento necesario para poder hacer predicciones con nuevas instancias.  

Estos factores intuimos que pueden ser el estatus social, el sexo, la edad y también tener familiares cerca. 

Asimismo, podemos ver si las pautas marcadas por la sociedad de "mujeres y niños primero" se cumplen cuando las personas se encuentran en situaciones de estres extremo.

De igual forma, y en el ámbito de la ciencia de datos, este dataset es importante porque es considerado un clásico y ha ayudado a muchos estudiantes a enfrentarse por primera vez a un problema de limpieza de datos, análisis estadísticos e incluso a técnicas de machine learning.



## **¿Qué problema pretende responder el dataset?**


Este dataset pretende responder a cuáles son los diferentes factores que afectaron a la posibilidad de supervivencia de personas en el accidente del Titanic.




******
# **Integración y selección de los datos**
******


## **Integración de los Datos**


La integración es un proceso que forma parte de la fase de limpieza de datos y se entiende como la fusión de datos para crear una estructura única que tenga la información necesaria para el posterior análisis de datos.

Existe la integración horizontal, que básicamente se compone de la adición de nuevos atributos a partir de otras fuentes mediante sus relaciones usando claves primarias y la integración vertical, que se basaría en añadir más instancias al juego de datos (siempre manteniendo la integridad de los atributos).

En nuestro caso, tenemos dos archivos train.csv y test.csv, dónde la diferencia entre ambos es que el test no tiene las etiquetas de la variable “Survived”.

**Integración Vertical**:

Con la finalidad de observar las distribuciones de las variables que serán base del estudio en la predicción de “Survived” integraremos verticalmente los dos archivos y así obtendremos un mayor número de datos para ver sus medidas de tendencia central y dispersión.  

Para que la integración vertical sea satisfactoria, las variables y estructura de ambos archivos debe coincidir, por tanto, crearemos un dataframe train_sin_etiqueta que se integrará con las instancias de test.csv al cual llamaremos df_total_sin_etiqueta.  

Observamos que la integración es satisfactoria puesto que las instancias ahora son 1309 (891 + 418).  







```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación archivo train_sin_etiqueta.csv

etiquetas <- subset(train, select = Survived)
train_sin_etiqueta <- subset(train, select = -Survived)

# Integración archivos train.csv y test.csv
df_total_sin_etiqueta = rbind(train_sin_etiqueta, test)
dim(df_total_sin_etiqueta)

# Guardamos el archivo con el nombre Titanic_global_sin_etiqueta.csv
write.csv(df_total_sin_etiqueta, "Titanic_global_sin_etiqueta.csv", row.names = FALSE)
```

**Integración Horizontal**:

Los archivos en la plataforma Kaggle no exponen ni fuentes externas ni csv adicionales que definan nuevas variables que se puedan integrar horizontalmente a nuestro juego de datos.  



**Comprobación de líneas duplicadas**:



Comprobamos si hay líneas duplicadas en el dataframe usando `duplicated`. No existen registros duplicados, pero sí detectamos dos pares de personas con el mismo nombre. Para asegurarnos que se trata de personas diferentes, buscamos los registros que tengan los nombres Connolly, Miss. Kate o Kelly, Mr. James.   

Podría tratarse de la misma persona que ha comprado dos billetes, pero en estos registros vemos que las personas tienen edades diferentes y no hay motivo para pensar que se trata de duplicados.  



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Chequeo de líneas duplicadas
df_total_sin_etiqueta[duplicated(df_total_sin_etiqueta),]

df_total_sin_etiqueta[duplicated(df_total_sin_etiqueta[c("Name","Sex")]),]
df_total_sin_etiqueta[df_total_sin_etiqueta$Name=="Kelly, Mr. James" | df_total_sin_etiqueta$Name == "Connolly, Miss. Kate",]

```


## **Selección de los Datos**


La selección se puede entender como un primer filtro de los datos, no solamente a través de poner límites a los valores de algunas instancias o elegir algún valor cualitativo específico, sino también a través de la inspección de las correlaciones entre los atributos y la posterior eliminación del dataset de aquellos que sean redundantes.

Debido a que el problema planteado es interpretar qué factores influyen en la supervivencia, a priori, no sabríamos si debemos descartar alguna variable o no (eliminación de la variable del estudio) o si deberíamos filtrar los datos, ya sean numérica o categóricamente.

No obstante, en esta sección eliminaremos la variable “Name” porque no es de mucha utilidad para nuestros análisis ya que el nombre no debería influir a priori en la supervivencia de los viajeros y también la variable “PassengerId” puesto que simplemente es un identificador.


Por lo tanto, además de esta primera selección relizada, esta fase del proceso la dejaremos abierta en este punto y retomaremos una vez la exploración y análisis nos vaya indicando qué debemos seleccionar y/o filtrar. A continuación, se hace una lista de las selecciones realizadas en este apartado y a posteriori.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos variables Name
keep.cols <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Ticket", "Fare", "Cabin", "Embarked")
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```



Variable Modificada | Tipo de selección | Apartado realizado | Motivo
------------------- | ----------------- | ------------------ | ------
Name|Eliminación|2.2|Variable no útil al ser independiente al estudio
PassengerId|Eliminación|2.2|Variable no útil al ser un simple identificador
Ticket|Eliminación|2.3|Usada para crear nueva variable y ya no es útil
Fase|Eliminación|2.3|Usada para crear nueva variable y ya no es útil
Cabin|Eliminación|3.1|Existencia masiva de valores nulos	


## **Creación de nuevas variables**

Se ha detectado que hay números de billetes duplicados. Esto indica que hay dos tipos de tickets:

•	Individuales  
•	Grupales

Se observa que la variable “Fare” muestra el mismo precio para los tickets grupales, por tanto, para saber realmente el precio del ticket por viajero y también para poder usar correctamente la variable “Fare”, deberíamos saber de cuántas personas es el ticket grupal y después dividir la variable “Fare” for dicha cantidad.

Crearemos una columna con el recuento de billetes con el mismo id para cada pasajero y otra con el precio unitario.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación variable con el contaje de los tickets con mismo nombre
df_total_sin_etiqueta$Count.ticket <- (df_total_sin_etiqueta%>%group_by(Ticket)%>%mutate(count=n()))$count
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación variable con el precio unitariocontaje de los tickets con mismo nombre
df_total_sin_etiqueta$Unit.price <- df_total_sin_etiqueta$Fare / df_total_sin_etiqueta$Count.ticket
```




Selección de datos inicial a posteriori

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos variable Name
keep.cols <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Cabin", "Embarked", "Count.ticket", "Unit.price")
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```






******
# **Limpieza de datos**
******

Hay que mencionar que se la limpieza de datos en este proyecto en particular debe afectar tanto al archivo train.csv como al test.csv, por tanto, limpiaremos los datos en base al dataframe global creado anteriormente (df_total_sin_etiqueta).





## **¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?**


### **Elementos vacíos en el dataset**

Comprobaremos si existen valores nulos o inexistentes en el juego de datos. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Overview of the data - Type = 1
ExpData(data=df_total_sin_etiqueta,type=1)

# Structure of the data - Type = 2
ExpData(data=df_total_sin_etiqueta,type=2)

```

Una vez que sabemos que tenemos valores nulos, cuántos tenemos y sabemos las variables afectadas, se decide la estrategia para imputar dichos valores


**Variable Cabin**:

Observamos que la variable “Cabin” tiene 1014 valores nulos de 1309, por tanto, se decide eliminar dicha variable por la imposibilidad de realizar una imputación generalizada.



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos variable Cabin
keep.cols <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Embarked", "Count.ticket", "Unit.price")
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```

**Variable Age**:

El número de registros de Age que son NA representan aproximadamente el 20% de los registros totales. 

Este dataset contiene variables categóricas y numéricas y para imputar los valores nulos de la variable Age podemos usar el método `kNN`. Aplicamos la función e imputamos los valores NA usando todos los demás campos del dataset y con un valor de k igual a 3. El algoritmo busca los registros de los 3 pasajeros más parecidos (cercanos según la distancia Gower) al que contiene un valor nulo y usa los datos de edades de estos pasajeros para imputar el valor faltante.

Una vez ejecutado el algoritmo para imputar los valores, volvemos a comprobar si existen valores NA y podemos confirmar que todos los NA para la variable edad han sido imputados.









```{r echo=TRUE, message=FALSE, warning=FALSE}

# Imputación de valores a los valores nulos de la variable age
df_total_sin_etiqueta <- kNN(df_total_sin_etiqueta, k=3)[1:10]
head(df_total_sin_etiqueta[is.na(df_total_sin_etiqueta$Age),])
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Comprobacion de la no existencia de registros nulos para la variable age después de la imputación.
sum(is.na(df_total_sin_etiqueta$Age))
```


**Variable Embarked**:

Se observa que la mayoría de las instancias pertenecen a la categoría S, por tanto, las instancias con valores nulos en esta variable, las imputaremos a S.



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Exploración del resumen de los datos de la varibale Embarked 
df_total_sin_etiqueta$Embarked <- as.factor(df_total_sin_etiqueta$Embarked)
summary(df_total_sin_etiqueta$Embarked)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Imputación clase mayoritaria a variable Embarked 
df_total_sin_etiqueta$Embarked[df_total_sin_etiqueta$Embarked == ""] <- "S"
summary(df_total_sin_etiqueta$Embarked)
```


**Variable Unit.price**:

Actuaremos de igual forma que con la variable Age e imputaremos a través del uso del kNN



```{r echo=TRUE, message=FALSE, warning=FALSE}

# Imputación de valores a los valores nulos de la variable age
df_total_sin_etiqueta <- kNN(df_total_sin_etiqueta, k=3)[1:10]
head(df_total_sin_etiqueta[is.na(df_total_sin_etiqueta$Unit.price),])
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

```







### **Gestión de los valores iguales a “cero” en el dataset**:


Ahora comprobamos las variables que toman valores igual a cero sin que tenga sentido que tomen este tipo de valor.   

La variable que representa la "clase" toma valores iguales a cero y consideramos que es correcto, lo mismo ocurre con las variables SibSp, Parch, donde consideramos normal que existan valores iguales a cero, significa que los pasajeros viajaban solos.  

En cambio, los valores iguales a cero para la variable Unit.price son algo más extraños. Entre los pasajeros que tienen un Unit.price igual a cero hay personas que viajaban en primera, segunda y tecera clase.  

La idea que un ticket sea gratuito no sería posible, por tanto, volveremos a aplicar el método kNN para imputar estos valores.  

Primero cambiaremos el valor de cero a NA y después actuaremos como en el apartado anterior.


```{r echo=TRUE, message=FALSE, warning=FALSE}

df_total_sin_etiqueta$Unit.price[df_total_sin_etiqueta$Unit.price == "0"] <- NA

# Imputación de valores a los valores ceros de la variable Unit.price
df_total_sin_etiqueta <- kNN(df_total_sin_etiqueta, k=3)[1:10]
head(df_total_sin_etiqueta[is.na(df_total_sin_etiqueta$Unit.price),])
df_total_sin_etiqueta <- df_total_sin_etiqueta[keep.cols]

# Comprobacion de la no existencia de registros ceros para la variable Unit.price después de la imputación.
sum(is.na(df_total_sin_etiqueta$Unit.price))
```



**Valores extremos** 

No hemos encontrado valores que estén fuera de un rango razonable. Las comprobaciones las hemos hecho anteriormente con `sapply(df, summary)`.  

Volvemos a visualizar boxplots para las variables numéricas que tenemos: Age y Fare.  


```{r echo=TRUE, message=FALSE, warning=FALSE}

oldpar = par(mfrow = c(2,2), mar=c(2,2,2,2))

# Boxplot variable Age
boxplot(df_total_sin_etiqueta$Age, main="Boxplot Variable Age",ylab="Edad (años)")
print("Boxplot Stats Variable Age\n")
boxplot.stats(df_total_sin_etiqueta$Age, coef = 1.5, do.conf = TRUE, do.out = TRUE)

# Boxplot variable Age
boxplot(df_total_sin_etiqueta$Unit.price, main="Boxplot Variable Unit.price",ylab="Precio billete unitario")
print("Boxplot Stats Variable Fare\n")
boxplot.stats(df_total_sin_etiqueta$Unit.price, coef = 1.5, do.conf = TRUE, do.out = TRUE)
```

El boxplot muestra que hay outliers en estas dos variables. La mayoría de los pasajeros eran jóvenes, aunque también encontramos pasajeros de más de 65 años. En cuanto a la variable Unit.price, se comprueba que a medida que el precio sube, la clase va bajando de 3 a 2 y de 2 a 1, con lo cual no hay razón porqué pensar que los precios no son reales. En la tabla siguiente podemos visualizar algunos de los pasajeros que pagaron un precio de billete alto. Notamos que todos son de primera clase.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Muestra de varios precios de billetes unitarios en el rango alto
tail(df_total_sin_etiqueta[df_total_sin_etiqueta$Unit.price>30,], 15)
```


Aunque se acepte que los precios son reales, es cierto que hay uno que es extremadamente alto y, aunque cierto, podría desvirtuar posibles futuras predicciones, por tanto se estima que se podría cambiar por la media de Unit.price agrupado por la primera clase, para tener un valor imputado más real.  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Imputación del valor máximo de Unit.price
df_price_Pclass <- aggregate( df_total_sin_etiqueta$Unit.price ~ df_total_sin_etiqueta$Pclass, df_total_sin_etiqueta, mean )
mean_Unit.price <- df_price_Pclass[2][[1]][1]

```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Muestra de varios precios de billetes unitarios en el rango alto
max_Unit.price <- max(df_total_sin_etiqueta$Unit.price)
max_Unit.price

df_total_sin_etiqueta$Unit.price[df_total_sin_etiqueta$Unit.price == max_Unit.price] <- mean_Unit.price
mean_Unit.price
```

```{r echo=TRUE, message=FALSE, warning=FALSE}

oldpar = par(mfrow = c(2,2), mar=c(2,2,2,2))

# Boxplot variable Age
boxplot(df_total_sin_etiqueta$Age, main="Boxplot Variable Age",ylab="Edad (años)")
print("Boxplot Stats Variable Age\n")
boxplot.stats(df_total_sin_etiqueta$Age, coef = 1.5, do.conf = TRUE, do.out = TRUE)

# Boxplot variable Age
boxplot(df_total_sin_etiqueta$Unit.price, main="Boxplot Variable Unit.price",ylab="Precio billete unitario")
print("Boxplot Stats Variable Fare\n")
boxplot.stats(df_total_sin_etiqueta$Unit.price, coef = 1.5, do.conf = TRUE, do.out = TRUE)
```



******
# **Análisis de datos**
******

Una vez limpiado el archivo que contenía las líneas de los conjuntos train y test, deberemos separar otra vez los conjuntos ya que únicamente tenemos datos de la etiqueta para el conjunto de entrenamiento.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Guardamos en disco el archivo global
write.csv(df_total_sin_etiqueta, "Titanic_global_sin_etiqueta.csv", row.names = FALSE)

```


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creación del conjunto de train y test después de la limpieza del dataset
train <- df_total_sin_etiqueta[1:train_rows, ]
test <- df_total_sin_etiqueta[(train_rows + 1):(train_rows+test_rows), ]

```


Y añadimos las etiquetas al conjunto de train:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Adición de las etiquetas al conjunto de entrenamiento
train <- cbind(train, etiquetas )
```

Guardamos en disco los archivos train y test procesados y "limpios" preparados para su posterior análisis.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Guardamos en disco los archivos procesados
write.csv(train, "train_processed.csv", row.names = FALSE)
write.csv(test, "test_processed.csv", row.names = FALSE)
```


**Screening**  

Antes de crear las visualizaciones determinamos que las variables numéricas son:  Age y Unit.price que corresponden a la edad de los pasajeros y el precio unitario del billete.  

**OLGA: revisar aquí, si las variables son categóricas o no, parece que nos va mejor que no lo sean**
Survived, Sex, Embarked son variables categóricas y Pclass, SibSp, Parch son variables categóricas ordinales (existen rangos en los valores de las variables).  

Realizamos las transformaciones oportunas para guardar las variables con sus tipos correspondientes.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Categóricas
train$Survived <- as.factor(train$Survived)
train$Sex <- as.factor(train$Sex)

# Categóricas ordinales
#train$Pclass <- factor(train$Pclass, levels= c(1, 2, 3))
#train$SibSp <- factor(train$SibSp, levels = c(0, 1, 2, 3, 4, 5, 8))
#train$Parch <- factor(train$Parch, levels = c(0, 1, 2, 3, 4, 5, 6, 9))

```


Creamos una función que nos facilite visualizar las distribuciones de las variables, así como detectar posibles valores extremos.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

visualiz <- function(data, colm, facet.colm, title, facetPlot=FALSE){
oldpar = par(mfrow = c(2,2), mar=c(2,2,2,2))
truehist(data[[colm]], main = title)
abline(v = mean(data[[colm]]), col="red", lwd=3, lty=2);
abline(v = median(data[[colm]]), lwd=3, lty=2, col="blue");
qqnorm(data[[colm]], main = title);qqline(data[[colm]], col = 2 )
if (facetPlot==TRUE) {
  boxplot(data[[colm]]~data[[facet.colm]], main = paste("Survived by", title))
}

boxplot(data[[colm]], main = title)
}
```


**Visualización de las variables numéricas**  

Los pasajeros que tienen edades entre los cuantiles 25 y 75 tienen entre 20 y 40 años. La edad mediana para los pasajeros que sobrevivieron y los que no es muy similar.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz(train, "Age", "Survived", "Age", facetPlot=TRUE)
```



Si vemos la variable Unit.price (precio unitario del billete), la mayoría de los pasajeros pagaron muy poco por el billete. Aquí en el boxplot encontramos outliers pero consideramos que no deberíamos descartar estas entradas ya que hay pocos pasajeros que pagaron un importe alto por el billete y esta información puede ser muy interesante para predecir la posibilidad de supervivencia: ¿Viajar en una clase privilegiada aumenta la posibilidad de sobrevivir?  

En el boxplot además podemos ver que las personas que sobreviven tienen una mediana más alta en el precio del billete. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz(train, "Unit.price", "Survived", "Unit.price", facetPlot=TRUE)
```


A continuación visualizamos los datos para las variables Class, Sex, Siblings/Spouse, Parents/Children  



```{r echo=TRUE, message=FALSE, warning=FALSE}
oldpar = par(mfrow = c(2,3), mar=c(2,2,2,2))

plot(table(train$Pclass, train$Survived), col = c("black", "orange"), main="Class")

plot(table(train$Sex, train$Survived), col = c("black", "orange"), main="Sex")

plot(table(train$SibSp, train$Survived), col = c("black", "orange"), main="Siblings/Spouse")

plot(table(train$Parch, train$Survived), col = c("black", "orange"), main="Parents/Children")

plot(table(train$Embarked, train$Survived), col = c("black", "orange"), main="Embarked")

plot(table(train$Count.ticket, train$Survived), col = c("black", "orange"), main="Embarked")

```


Las personas que viajaban en tercera clase tienen la menor proporción de supervivencia comparando con las personas que viajaban en primera clase. Las mujeres que viajaban en el titanic sobrevivieron en su mayoría. Los hombres sobrevivieron en mucho menor proporción.   

La mayoría de personas viajaba sin familiares (hermanos, pareja, padres o hijos) y parece ser que el porcentaje de supervivencia es algo más alto en personas que tenían familiares a bordo.   

La mayoría de personas embarcaron en el punto S, pero el mayor porcentaje de supervivencia lo tienen las personas que embarcaron en C.  

Los pasajeros que viajaban varias personas con el mismo billete también tienen una mayor supervivencia ( hasta 4 pasajeros ). 1 o más de 4 pasajeros con el mismo billete tienen la misma proporción de supervivencia.  

**Análisis bivariable**  

Vamos a visualizar algunos plots que nos permiten ver la supervivencia de pasajeros combinando dos variables.  

```{r echo=TRUE, message=FALSE, warning=FALSE}

grid.newpage()

sex.class <- ggplot(data=train, aes(x=Sex, fill=Survived))+geom_bar(position = 'fill')+facet_wrap(~Pclass)+ scale_fill_manual(values=c("black", "orange"))
sibs.class <- ggplot(data=train, aes(x=SibSp, fill=Survived))+geom_bar(position = 'fill')+facet_wrap(~Pclass)+ scale_fill_manual(values=c("black", "orange"))
parch.class <- ggplot(data=train, aes(x=Parch, fill=Survived))+geom_bar(position = 'fill')+facet_wrap(~Pclass)+ scale_fill_manual(values=c("black", "orange"))
embark.class <- ggplot(data=train, aes(x=Embarked, fill=Survived))+geom_bar(position = 'fill')+facet_wrap(~Pclass)+ scale_fill_manual(values=c("black", "orange"))

grid.arrange(sex.class, sibs.class, parch.class, embark.class,  ncol=2)

```

Las mujeres que viajaban en primera y segunda clase sobrevivieron casi todas. Los hombres sobrevivieron en mucho menor medida, incluso los hombres que viajaron en primera clase.  

Las personas que viajaban con hermanos o pareja en primera clase sobrevivieron en mayor medida que las personas que viajaron solas. En primera y segunda clase no hay personas que viajasen con más de 3 hermanos. En tercera clase hay personas que viajaron con hasta 8 hermanos en este caso un menor número de hermanos (excepto cero) parece indicar una mayor supervivencia.  

También hemos visualizado la supervivencia en función del lugar donde los pasajeros embarcaron en el Titanic. Los pasajeros de tercera clase que embarcaron en el punto S han tenido menos proporción de supervivencia que los demás. Los pasajeros de segunda clase que embarcaron en Q sobrevivieron en mayor proporción que los pasajeros de segunda clase que embarcaron en otros puntos. Para los pasajeros de primera clase el punto de embarque con mayor porcentaje de superviviencia es C.   


```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data=train, aes(x=Sex, fill=as.factor(Pclass)))+geom_bar(position = 'fill')+facet_wrap(~Embarked)+ scale_fill_manual(values=c("black", "orange", "red"))
```
```{r}
ggplot(data=train, aes(x=Embarked, fill=as.factor(Survived)))+geom_bar(position = 'fill')+ scale_fill_manual(values=c("black", "orange", "red"))
```


Visualizamos la supervivencia usando las variables de la clase en la que viaja el pasajero y el número de personas que viajan con el mismo billete.  

En el Titanic viajaron familias enteras de hasta 7 personas en primera clase y incluso de 11 personas en tercera clase. La supervivencia de personas que viajaban sobre el mismo billete en tercera clase es comparable con el mismo dato en segunda clase.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data=train, aes(x=Count.ticket, fill=Survived))+geom_bar(position = 'fill')+facet_wrap(~Pclass)+ scale_fill_manual(values=c("black", "orange", "red"))
```


## Análisis de los datos.  

### Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).  

La pregunta que planteamos inicialmente es si entre las variables que tenemos en el dataset existen algunas que influyen en mayor medida en la supervivencia de los pasajeros del Titanic. En los análisis anteriores hemos comprobado visualmente que las personas de primera clase han sobrevivido en mayor medida, que las mujeres y los niños tienen una mayor proporción de supervivencia. También hemos visto que personas que viajan acompañadas, ya sea por familia o amigos, tiene una proporcion de supervivencia algo mejor.   

Vamos a usar estos datos para analizar el dataset en mayor profundidad. Para ello necesitamos datasets especializados.  











**CARLOS: NO VEO PQ NO HACEMOS UN GRUPO CON LA PCLASS 3**
**Olga: NO hay pomivo por el que no hacer class3, pero pensaba que nos ibamos a centrar en con cuantos viajan y dejar lo demás de lado.. no sé **

OLGA: Si seguimos con lo que hemos hablado, de centrarnos en si los pasajeros viajan solos o no, debemos separar estos 3 pares de datasets.**las variables sibsp, parch están como factor, voy a comentar la parte donde se les transforma en factor..** 
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por pasajeros que viajaban solos o acompañados
train.single <- train[train$Count.ticket=="1",]
train.many <- train[train$Count.ticket>1,]
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por pasajeros que viajaban solos o acompañados
train.spouse <- train[train$SibSp>0,]
train.not.spouse <- train[train$sibsp==0,]
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por pasajeros que viajaban solos o acompañados
train.children <- train[train$Parch>10,]
train.no.children <- train[train$Parch==0,]
```







```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframes por clase de pasajero
train.first <- train[train$Pclass==1,]
train.second <- train[train$Pclass==2,]
train.first.second <- train[train$Pclass==1 | train$Pclass==2,]
train.first.second$Pclass <- factor(train.first.second$Pclass, levels = c(1,2))
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por sexo del pasajero
train.male <- train[train$Sex=="male", ]
train.female <- train[train$Sex=="female",]
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Dataframe por edad del pasajero
train.young <- train[train$Age<18,]
train.older <- train[train$Age>=18,]
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
train.survived <- train[train$Survived==1,]
train.not.survived <- train[train$Survived==0,]
```





### Comprobación de la normalidad y homogeneidad de la varianza.  

**Normalidad** 
```{r echo=TRUE, message=FALSE, warning=FALSE}
 visualiz1 <- function(D1, D2, name1, name2, title){
   oldpar = par(mfrow = c(2,2), mar=c(2,2,2,2))
  truehist(D1, main = paste(name1," ", title))
  abline(v = mean(D1), col="red", lwd=3, lty=2);
  abline(v = median(D1), lwd=3, lty=2, col="blue");
  qqnorm(D1, main = paste(name1, " ", title));qqline(D1, col = 2 )
  truehist(D2, main = paste(name2," ", title))
  abline(v = mean(D2), col="red", lwd=3, lty=2);
  abline(v = median(D2), lwd=3, lty=2, col="blue");
  qqnorm(D2, main = paste(name2," ", title)); qqline(D2, col = 2 )

}
```


**Variable age**

Visualizamos los datos de la edad para personas que sobrevivieron en el hundimiento frente a personas que no sobrevivieron.  

La media y la mediana de los pasajeros que sobrevivieron están muy cerca. Las personas que no sobrevivieron tienen una edad mediana más baja que la edad media. Los valores de estos dos indicadores de tendencia central son más altos para personas que no sobrevivieron: las personas que muerieron tenían una media de edad algo más alta que los que sobrevivieron.  

Según el qqplot las dos distribuciones son cercanas a la normal. Según el teorema del límite central podemos asumir la distribución normal de la media de estas dos muestras ya que sus tamaños son mayores que 30 observaciones.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
visualiz1(train.survived$Age, train.not.survived$Age, "Survived", "Not Survived", "")
```


Comprobaremos de la igualdad de las varianzas entre los conjuntos de datos de pasajeros que sobrevivieron y no. Para ello usamos la función `var.test`.  

El contraste de varianzas se realiza mediante un contraste de hipótesis, donde aceptar H0 significaría que las varianzas son iguales. 

El valor p-value que obtenemos es de 0.15. Este valor indica que rechazando la hipótesis nula de igualdad de varianzas probablemente estaríamos comentiendo un error. Las varianzas en la edad de los pasajeros que sobrevivieron y los que no sobrevivieron son iguales y podemos hacer esta afirmación con un nivel de confianza del 95%.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Age, train.not.survived$Age)
```


**Variable Unit price: precio del billete unitario** 

Visualizamos el precio del billete unitario para los pasajeros que sobrevivieron frente a los que no. Podemos ver que la media y la mediana del precio de billete para los pasajeros que sobrevivieron están bastante separadas. El precio que corresponde a la mediana es alrededor de 13 y la media es más cercana a 20. Existe esta diferencia porque la distribución tiene una cola larga a la derecha, tenemos pasajeros que pagaron un precio muy alto por sus billetes.  

La mayoría de los pasajeros que no sobrevivieron pagaron un precio bajo por el billete, hay pocas personas que pagaron precios más altos y no sobrevivieron. 

Ninguna de las dos distribuciones es normal, aunque para el fin de hacer un contraste de hipótesos sobre la media podemos asumir que la media poblacional se distribuye normalmente (teorema del límite central).  

```{r}
visualiz1(train.survived$Unit.price, train.not.survived$Unit.price, "Survived", "Not Survived", "Unit price")
```

Realizamos el test de igualdad de las varianzas para el precio del billete para pasajeros que sobrevivieron frente a los que no sobrevivieron. El valor p nos indica que podemos rechazar H0, es decir, las varianzas entre estos dos grupos de pasajeros son diferentes.  

En los histogramas podemos ver que los pasajeros que sobrevivieron de media pagaron más por sus billetes. Tanto en el grupo de supervivientes como de no supervivientes la media es mayor que la mediana, dado que tenemos outliers de precio de billete unitario muy alto.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Unit.price, train.not.survived$Unit.price)
```


**Variable SibSp: pareja o hermanos**  

```{r}
visualiz1(train.survived$SibSp, train.not.survived$SibSp, "Survived", "Not Survived", "Siblings / Spouse")
```



```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$SibSp, train.not.survived$SibSp)
```
**Variable Parch: padres o hijos** 

```{r}
visualiz1(train.survived$Parch, train.not.survived$Parch, "Survived", "Not Survived", "Parents/Children")
```

El test de igualdad de las varianzas indica que no podemos rechazar la hipótesis nula. Entre los grupos que sobrevivieron y los que no sobrevivieron las varianzas de la variable Parch son iguales.
```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Parch, train.not.survived$Parch)
```

**Variable Count.ticket: número de personas que viajaban con un mismo billete**  

Visualizamos un histograma que muestra la frecuencia de recuento de billetes: pasajeros que viajaban solos hasta pasajeros que viajaban con muchos acompañantes.  

La media para el recuento de billetes es de 2 mientras que la mediana es 1. 

```{r echo=TRUE, message=FALSE, warning=FALSE}

visualiz1(train.survived$Count.ticket, train.not.survived$Count.ticket, "Survived", "Not Survived", "Ticket count")
```

En este caso tenemos un valor p muy bajo y por lo tanto podemos aceptar H1 que indica que las varianzas de la variable Count.ticket son diferentes en el grupo de supervivientes y no supervivientes.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
var.test(train.survived$Count.ticket, train.not.survived$Count.ticket)
```


```{r}
```


```{r}
```


```{r}
```

### Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.   


**Contraste de hipótesis sobre el sexo y nivel de supervivencia**


¿La proporción de supervivencia en hombres es inferior a la de las mujeres?  


Acorde con la pregunta planteada, realizaremos un contraste de hipótesis con las siguientes hipótesis de partida:  

Hipótesis nula - H0: La proporción de hombres que sobreviven es igual o mayor a 50% -> H0: p >= p0, siendo p0 = 0.5  
Hipótesis alternativa - H1: La proporción de hombres es menor a 50% -> H1: p < p0, siendo po = 0.5  


Este contraste de hipótesis representa un test de la proporción de la población por la cola izquierda, por tanto, el valor p0 representará, bajo la hipótesis nula, el límite inferior de la supuesta verdadera proporción de la población.  
Este contraste rechazará la HO si el estadístico calculado es menor o igual al valor crítico (con signo negativo) al nivel de significación estimado.  

El hecho que la proporción de hombres que sobreviven sea menor que 0.5, implicaría que la proporción de hombres que sobreviven es inferior a la de las mujeres.  


Debido a que es un contraste de hipótesis sobre proporción de una muestra, y esta muestra es considerada grande (n > 30), podremos definir un estadístico de contraste como una observación de una variable aleatoria que se distribuye aproximadamente como una N(0,1).  

Debido al planteamiento de la hipótesis nula y su alternativa y por cómo se han descrito las hipótesis H0 y H1, se observa que la hipótesis alternativa es unilateral, puesto que se plantea como un límite a un solo valor dado.  



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Fijamos un nivel de significación

alfa <- 0.05
```


Determinamos el estadístico de contraste, en este caso, la muestra es grande y proviene de una distribución de Bernoulli de parámetro p, con lo cual, según el Teorema del Límite Central podremos utilizar el estadístico de contraste mostrado anteriormente.  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Determinación del estadístico de contraste

train.survived_M <- train.survived[train.survived$Sex=="male",]
train.survived_F <- train.survived[train.survived$Sex=="female",]



n_Sex <- length(train.survived$Sex)

n_Sex_M <- length(train.survived_M$Sex)

n_Sex_F <- length(train.survived_F$Sex)



# Proporción muestral de hombres
p_hat <- n_Sex_M/n_Sex


# Proporción hipotesis nula
p_0 <- 0.5


# Estadístico empleado z_p
z_p = (p_hat - p_0)/sqrt(p_0 * (1 - p_0)/n_Sex) 

# Cálculo de valores críticos para el valor de significación asignado

z_p.alfa = qnorm(1-alfa) 


# Cálculo del valor P en nuestro contraste de hipótesis

valor_p_Sex = pnorm(z_p) 
 

data.frame(n_Sex, n_Sex_M, n_Sex_F, p_hat, p_0, z_p, -z_p.alfa, valor_p_Sex)
```



Tal y como se ha planteado H0 y H1, siendo H1 p < 0.5, rechazaremos H0 si el valor del estadístico z_p es menor que el valor crítico (en signo negativo), siendo este el caso -6.70 < -1.64.  


Según el estadístico de contraste utilizado y el valor crítico calculado, al ser el primero (-6.70) menor que el segundo (-1.64), al 0.05 de nivel de significancia, podemos rechazar la hipótesis nula de que la proporción de supervivencia en hombres es mayor o igual a 50% respecto al de las mujeres.  

De igual forma, al ser valor p casi nulo y por tanto menor que nuestro nivel de significación (0.05), el valor p es significativo y podemos rechazar, confirmando el contraste anterior, la hipótesis nula.  


Siguiendo la misma metodología, responderemos a las siguientes preguntas:


**¿La proporción de supervivencia en menores es inferior a la de los mayores?** 

Hipótesis nula - H0: La proporción de menores que sobreviven es igual o mayor a 50% -> H0: p >= p0, siendo po = 0.5  
Hipótesis alternativa - H1: La proporción de menores es menor a 50% -> H1: p < p0, siendo po = 0.5  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Determinación del estadístico de contraste

train.survived_Y <- train.survived[train.survived$Age<18,]
train.survived_O <- train.survived[train.survived$Age>=18,]


n_Age <- length(train.survived$Age)

n_Age_Y <- length(train.survived_Y$Age)

n_Age_O <- length(train.survived_O$Age)



# Proporción muestral de menores
p_hat <- n_Age_Y/n_Age


# Proporción hipotesis nula
p_0 <- 0.5

# Estadístico empleado z_p
z_p = (p_hat - p_0)/sqrt(p_0 * (1 - p_0)/n_Age) 

# Cálculo de valores críticos para el valor de significación asignado

z_p.alfa = qnorm(1-alfa) 

# Cálculo del valor P en nuestro contraste de hipótesis

valor_p_Age = pnorm(z_p) 

data.frame(n_Age, n_Age_Y, n_Age_O, p_hat, p_0, z_p, -z_p.alfa, valor_p_Age)
```



**OLGA** algo no va bien aquí, este -4.43 de donde sale? lo de hombres y mujeres tampoco es correcto

Según el estadístico de contraste utilizado y el valor crítico calculado, al ser el primero (-4.43) menor que el segundo (-1.64), al 0.05 de nivel de significancia, podemos rechazar la hipótesis nula de que la proporción de supervivencia en hombres es mayor o igual a 50% respecto al de las mujeres.  
  
De igual forma, al ser valor p casi nulo y por tanto menor que nuestro nivel de significación (0.05), el valor p es significativo y podemos rechazar, confirmando el contraste anterior, la hipótesis nula.  



**¿La proporción de supervivencia en viajeros con billete único es inferior a la de los viajeros con billete en conjunto?**

Hipótesis nula - H0: La proporción de viajeros con billete único que sobreviven es igual o mayor a 50% -> H0: p >= p0, siendo po = 0.5  
Hipótesis alternativa - H1: La proporción de viajeros con billete único es menor a 50% -> H1: p < p0, siendo po = 0.5  


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Determinación del estadístico de contraste

train.survived_S <- train.survived[train.survived$Count.ticket==1,]
train.survived_My <- train.survived[train.survived$Count.ticket>1,]

n_Count.ticket <- length(train.survived$Count.ticket)

n_Count.ticket_S <- length(train.survived_S$Count.ticket)

n_Count.ticket_My <- length(train.survived_My$Count.ticket)



# Proporción muestral de menores
p_hat <- n_Count.ticket_S/n_Count.ticket

# Proporción hipotesis nula
p_0 <- 0.5

# Estadístico empleado z_p
z_p = (p_hat - p_0)/sqrt(p_0 * (1 - p_0)/n_Count.ticket) 

# Cálculo de valores críticos para el valor de significación asignado

z_p.alfa = qnorm(1-alfa) 

# Cálculo del valor P en nuestro contraste de hipótesis

valor_p_Count.ticket = pnorm(z_p) 

data.frame(n_Count.ticket, n_Count.ticket_S, n_Count.ticket_My, p_hat, p_0, z_p, -z_p.alfa, valor_p_Count.ticket)
```


Según el estadístico de contraste utilizado y el valor crítico calculado, al ser el primero (-10.92) menor que el segundo (-1.64), al 0.05 de nivel de significancia, podemos rechazar la hipótesis nula de que la proporción de supervivencia en hombres es mayor o igual a 50% respecto al de las mujeres.  

De igual forma, al ser valor p casi nulo y por tanto menor que nuestro nivel de significación (0.05), el valor p es significativo y podemos rechazar, confirmando el contraste anterior, la hipótesis nula.   



**Relación entre supervivencia y billete único o grupal**

Utilizamos el test Chi cuadrado para comprobar si los pasajeros de primera clase sobrevivieron en mayor medida que los pasajeros de segunda clase.  

El test se aplica en R con un nivel de confianza por defecto del 95%.  

Crearemos dos tablas de contingencia entre las variables que indican supervencia y la que indica el tipo de billete. Una primera en valores absolutos, y una segunda mostrando las proporciones.



```{r echo=TRUE, message=FALSE, warning=FALSE}

# Tabla de contingencia Survived - Tipo Billete

train$ticket_tipo[train$Count.ticket==1] = "Único"
train$ticket_tipo[train$Count.ticket!=1] = "Grupal"

train$ticket_tipo <- as.factor(train$ticket_tipo)
table(train$Survived, train$ticket_tipo, dnn = c("Supervivencia", "Tipo Billete"))

# Tabla de contingencia en proporciones Survived - Tipo Billete
prop.table(table(train$Survived, train$ticket_tipo, dnn = c("Supervivencia (%)", "Tipo Billete (%)")))

length(train$ticket_tipo)
length(train$Survived)

```


Dos variables categóricas que forman parte de una tabla de contingencia pueden ser sujetas a un test de independencia. Este test puede ser representado for el ChiSquare Test mediante un contraste de hipótesis.  

El contraste se realizará para observar si las dos variables son independientes o no, por tanto, podemos plantear las hipótesis como se indica a continuación:  

Hipótesis nula - H0: Las variables Survived y Tipo Billete son independientes.  
Hipótesis alternativa - H1: Las variables Survived y Tipo Billete están relacionadas.  



```{r echo=TRUE, message=FALSE, warning=FALSE}

# Tabla de contingencia Survived y Tipo Billete
tabla_cont <- table(train$Survived, train$ticket_tipo, dnn = c("Supervivencia", "Tipo Billete"))
tabla_cont


# Comprobación con la función chisq.test()
chisq.test(tabla_cont)


```


El cálculo de los grados de libertad para una distribución Chi Square se calcula como df = (c - 1)(r - 1) donde c es el número´de columnas y r el número de filas. En nuestro caso c = r = 2, por lo tanto df = (2 - 1)(2 - 1) = 1.



```{r echo=TRUE, message=FALSE, warning=FALSE}

# Grados de libertad

gdl <- 1

# Nivel de confianza

ndc <- 0.95


# Valor Crítico
val_cri <- qchisq(ndc, gdl)
val_cri

```



Debido a que el estadístico Chi Square es mayor al valor crítico calculado de la distribución Chi Square (con un grado de libertad y con un nivel de significación de 0.05), podemos rechazar la hipótesis nula de que no hay relación entre Survived y Tipo de Billete, es decir, rechazamos la hipótesis al 95 % de nivel de confianza de que tales variables sean independientes.  

Como el valor de p es menor que el nivel de significancia, podemos rechazar la hipótesis nula de que las variables Survived y Tipo de Billete son independientes, cuadrando este resultado con los cálculos anteriores.

Por tanto, se puede afirmar al 95% de nivel de confianza que las variables Survived y Tipo de Billete **están relacionadas**.





**Contraste de hipótesis sobre la edad de supervivencia**

Planteamos la pregunta de investigación: Queremos saber si las personas que sobrevivieron eran más jóvenes que las personas que murieron en el accidente o, por el contrario, la edad para las personas que muerieron y sobrevivieron es similar.   

Nos encontramos ante el caso en el que podemos asumir la normalidad de las distribuciones de la media de las dos muestras pero sabemos que las varianzas de las muestras **(EL RESULTADO HA CAMBIADO)** son diferentes. Se trata de un test paramétrico de dos muestras. 
**OLGA: ok, entonces var.equal = TRUE**

H0: La media de edad de las personas supervivientes es la misma que de las personas que muerieron  
H1: La media de edad de las personas que murieron es mayor que la de las personas supervivientes.    

Usamos un test paramétrico definido por `t.test`


Con un valor p-value igual por debajo de 0.05 podemos aceptar la hipótesis H1. Con un nivel de confianza del 95% afirmamos que las personas que murieron en el Titanic tienen una media de edad más alta que las personas que sobrevivieron.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
t.test(train.not.survived$Age, train.survived$Age, alternative="greater", var.equal=TRUE)
```



**Correlaciones**




```{r echo=TRUE, message=FALSE, warning=FALSE}

# Relaciones cruzadas de las variables cuantitativas (correlaciones) para todos los datos.

col_var_cuantitativa_sin_ID <- c("Age", "SibSp", "Parch", "Count.ticket", "Unit.price")

df_var_cuantitativa <- df_total_sin_etiqueta[, col_var_cuantitativa_sin_ID]


pairs.panels(df_var_cuantitativa[,col_var_cuantitativa_sin_ID], 
             method = "pearson", 
             hist.col = "grey",
             density = TRUE,  
             ellipses = TRUE 
             )

```
**OLGA**
Para algunos modelos necesitaremos la variable en forma de texto, por lo tanto guardamos un dato alternativo sobre la supervivencia de los pasajeros: "Survived" para el valor 1 y "Died" para el valor 0 de la variable dependiente.  
```{r}
train$survived <- ifelse(train$Survived==1, "Survived", "Died")
```

```{r}
X <- train[c("Pclass", "Sex", "Age", "SibSp", "Parch", "Count.ticket", "Unit.price", "Embarked")]

y <- train[9]
y.1 <- train[10]
```

Partimos el conjunto train en subconjuntos de train y validación. De esta manera dispondremos de datos para comprobar el funcionamiento de los modelos que construyamos.  

```{r}
indexes = sample(1:nrow(train), size=floor((2/3)*nrow(train)))
trainX<-X[indexes,]
trainy<-y[indexes,]
validX<-X[-indexes,]
validy<-y[-indexes,]
train.1 <- data.frame(cbind(trainX, trainy))
trainy.1 <- y.1[indexes,]
validy.1 <- y.1[-indexes,]
```

**Regresión**   






Aplicamos una regresión logística para predecir la probabilidad de supervivencia usando como variable predictora la variable sexo.  

Según los datos que nos proporciona la función `summary` la variable sexo es significativa para predecir la supervivencia y ser de sexo masculino reduce la probabilidad de sobrevivir.  


```{r echo=TRUE, message=FALSE, warning=FALSE}

#model0=glm(formula=Survived~Sex, data=train, family=binomial(link=logit))
model0=glm(formula=trainy~Sex, data=train.1, family=binomial(link=logit))

summary(model0)
```
Calculamos los Odds Ratio. Los odds ratio indican que ser hombre es factor de protección para la clase 1 (sobrevivir). Los hombres están "protegidos" de la supervivencia en comparación con las mujeres.  


```{r echo=TRUE, message=FALSE, warning=FALSE}
exp(coefficients(model0))

```

Usamos los datos de validación para realizar una predicción de supervivencia. Tenemos que 75 instancias de supervivencia y 157 instancias de no supervivencia han sido predichas correctamente. 39 instancias de supervivencia real han sido predichas como no supervivencia. 26 instancias de no supervivencia fueron predichas incorrectamente como supervivencia.    

El modelo de regresión que utiliza únicamente la variable Sexo para predecir la supervivencia tiene una precisión del 78%.  

```{r}
newdata <- validX
probabilities <- model0 %>% predict(newdata[c("Sex")], type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)

# Matriz de confusión
conf.1 <- table(validy, predicted.classes)
conf.1

# Precisión
sum(diag(conf.1))/sum(colSums(conf.1))
```



Aplicamos una regresión logística para comprobar si las variables Sexo y Clase son significativas para la supervivencia en el accidente.  

Ambas variables son significativas y así lo indican los asteriscos junto a los valores Pr(>|z|).  

Ser hombre, viajar en clase 2 o clase 3 reduce la posibilidad de supervivencia con respecto a ser mujer y viajar en primera clase. Esto viene indicado por el signo negativo que acompaña el valor del coeficiente para Sexmale, Pclass2 y Pclass3.   

```{r echo=TRUE, message=FALSE, warning=FALSE}

model1=glm(formula=trainy~Sex+as.factor(Pclass), data=train.1, family=binomial(link=logit))
summary(model1)
```

Calculamos los odds ratio. Igual que en el caso anterior vemos que la probabilidad ser hombre y sobrevivir es mucho menor que la de ser mujer y sobrevivir. Por clases el OR indica que estar en segunda o tercera clase es factor de protección (pocas probable sobrevivir) respecto a la primera clase.  
```{r echo=TRUE, message=FALSE, warning=FALSE}
exp(coefficients(model1))
```



Realizamos la predicción sobre el conjunto de validación que obtuvimos y con el resultado creamos una matriz de confusión y calculamos la precisión. El resultado es igual que en la regresión anterior.  

```{r}

probabilities1 <- model1 %>% predict(newdata[c("Sex","Pclass")], type = "response")
predicted.classes1 <- ifelse(probabilities1 > 0.5, 1, 0)
# Matriz de confusión
conf.2 <- table(validy, predicted.classes1)
conf.2

# Precisión
sum(diag(conf.2)) / sum(colSums(conf.2))


```


Por último generamos un modelo que incluye todas las variables disponibles

En los datos hemos detectado que había hasta 8 pasajeros con el mismo billete. Posiblemente se tratara de familia o amigos. Usaremos esta variable para crear un modelo.  
```{r echo=TRUE, message=FALSE, warning=FALSE}


model2=glm(formula=trainy~Pclass+Sex+Age+factor(Count.ticket)+Embarked, data=train.1, family=binomial(link=logit))
summary(model2)

```

El resultado del modelo indica que cuando  tres o cuatro personas viajaban juntas, la probabilidad de sobrevivir aumentaba (signo positivo del coeficiente).  

Calculamos los ORS. Para las personas que viajaban con otra persona, otras dos o tres personas el "riesgo" de sobrevivir es mucho mayor.   

```{r echo=TRUE, message=FALSE, warning=FALSE}
exp(coefficients(model2))
```


```{r}

probabilities2 <- model2 %>% predict(newdata[c("Pclass","Sex","Age","Count.ticket", "Embarked")], type = "response")
predicted.classes2 <- ifelse(probabilities2 > 0.5, 1, 0)
# Matriz de confusión
conf.3 <- table(validy, predicted.classes2)
conf.3

# Precisión

sum(diag(conf.3)) / sum(colSums(conf.3))


```
**OLGA: Me preguntabas los modelos supervisados o no: ya estaba hecho el árbol rpart, he hecho otro rpart con cross validation y un random forest que no parece dar mejor resultado. Con esto yo creo que más que suficiente**

**Árboles de decisión CART**  

En primer lugar creamos un árbol de decisión para predecir la supervivencia de los pasajeros del Titanic tomando en cuanta las variables explicatovas del conjunto de entrenamiento y la etiqueta de clase (Supervivencia o no)   

```{r, echo=FALSE}
# Cargamos la librería
library(rpart.plot)
library(caret)

```


Usamos los datos del conjunto train para entrenar el modelo y visualizamos el árbol y los datos del modelo.  
```{r}
treeFit <- rpart(trainy~.,data=trainX,method ='class')
print(treeFit)
```
El árbol ha realizado las particiones de los datos en base a la variable Sex. Los pasajeros de sexo masculino, mayores de 14 años tienen como clase por defecto la no supervivencia. Los pasajeros que pagaron entre 26 y 31 dólares y menores de 52 años no sobreviven. Los pasajeros menores de 14 años si viajaban con menos de 3 hermanos casi todos sobreviven.  

Por otra parte, los pasajeros de sexo Femenino en que viajaban en tercera clase sobrevivieron si viajaban con menos de 5 personas (count ticket), si pagaron menos de 8.1 dólares y si tenían edad menor de 28 años. Todos los demás se clasifican como no supervivientes. Las mujeres en otras clases distintas de la tercera sobrevivieron en su mayoría.    

En el árbol podemos ver que se ha considerado variables bastante diferentes para clasificar a los hombres y a las mujeres. Para los hombres la edad ha sido un factor importante para la supervivencia, principalmente sobrevivieron los hombres menores de 14 años. En el caso de las mujeres el factor determinante ha sido la clase y las personas con las que viajaban.  

```{r}
# Árbol resultante.  
rpart.plot(treeFit)
```

Predecimos usando los datos de validación.  
```{r}
prediction <- predict(treeFit,newdata=validX,type ='class')
```

Con la matriz de confusión y el valor de Accuracy podemos ver que la predicción ha mejorado con respecto a la regresión logística.  

```{r}
confusionMatrix(prediction,validy)
```


**Árbol de decisión usando cross validation y búsqueda de mejor parámetro**   

Podemos entrenar un árbol de decisión usando cross validation y la búsqueda en rejilla. 
```{r}
library(caret)
library(lattice)

control <-  trainControl(method="repeatedcv", number=3, repeats=3, savePredictions = TRUE)
metric <- "Accuracy"
grid <- expand.grid(cp = seq(0.0001,0.05,0.001))
# Training of model.
model.boost <- train(y=as.factor(trainy), tuneGrid=grid,x=trainX, method="rpart",metric=metric, trControl=control)

# Summarize the results
print(model.boost)

```
Haremos la validación cruzada o crossvalidation con 10 folds y busqueda de los mejores parámetros usando el expand.grid. Utilizaremos la métrica Accuracy que mide el porcentaje de instancias correctas sobre total.  Entrenamos el modelo con los datos trainX y trainy, establecemos el método que es el mismo que aplicamos en el primer árbol de decisión de la pec (C5.0) como parámetro de la función.  



```{r}
model.boost$finalModel
prediction <- ifelse(predict(model.boost$finalModel, newdata=validX)[,1]>0.50, "0", "1")

table(prediction, validy)


```
```{r}
rpart.plot(model.boost$finalModel, box.col=c("red", "green"))
```


```{r}
model.boost$levels
```

```{r}
plot(model.boost)
```
Visualizamos las iteraciones de boosting vs la precisión. Tenemos la mayor precisión con 25 iteraciones.  


```{r}
predicted_model.boost <- predict(model.boost, newdata=validX)
cmat <- confusionMatrix(predicted_model.boost, as.factor(validy))
cmat
```



```{r}
#Defining the training controls for multiple models
fitControl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3,
savePredictions = 'final',
classProbs = T)

#Defining the predictors and outcome
predictors<-colnames(trainX)

```




```{r}
#Training the random forest model
model_rf<-train(trainX,y=as.factor(trainy.1),method='rf',trControl=fitControl,tuneLength=9)

#Predicting using random forest model
validX$pred_rf<-predict(object = model_rf,validX)

#Checking the accuracy of the random forest model
confusionMatrix(as.factor(validy.1),validX$pred_rf)
```
```{r}
plot(model_rf)
```





















## Including Plots




******
# **Representación de resultados**
******


## Tabla resumen de las variables cualitativas (datos completos)


Realizaremos una tabla resumen con las frecuencias relativas y las frecuencias absolutas de las variables cualitativas.
Creamos un dataframe auxiliar para generar nuestra tabla.

Calculamos, para todos los campos, la frecuencia relativa y absoluta a través del contaje dividido por el número total de filas del dataframe.

Creamos una tabla mediante la función kable().



```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

col_var_cualitativa_sin_ID <- c("Pclass", "Sex", "Embarked")

df_var_cualitativa <- df_total_sin_etiqueta[, col_var_cualitativa_sin_ID]

df_var_cualitativa$Sex <- as.factor(df_var_cualitativa$Sex)
df_var_cualitativa$Embarked <- as.factor(df_var_cualitativa$Embarked)


# Frecuencias relativas y absolutas de campo PClass
Pclass_table_frec <- (count(df_var_cualitativa$Pclass))
Pclass_table_cum <- (count(df_var_cualitativa$Pclass)/dim(df_var_cualitativa)[1])[2]

Pclass_table <- cbind (Pclass_table_frec, Pclass_table_cum)

# Frecuencias relativas y absolutas de campo Sex
Sex_table_frec <- (count(df_var_cualitativa$Sex))
Sex_table_cum <- (count(df_var_cualitativa$Sex)/dim(df_var_cualitativa)[1])[2]

Sex_table <- cbind (Sex_table_frec, Sex_table_cum)

# Frecuencias relativas y absolutas de campo Embarked
Embarked_table_frec <- (count(df_var_cualitativa$Embarked))
Embarked_table_cum <- (count(df_var_cualitativa$Embarked)/dim(df_var_cualitativa)[1])[2]

Embarked_table <- cbind (Embarked_table_frec, Embarked_table_cum)



# Unión de toda la tabla asignando el nombre de las columnas
df_var_cualitativa_table <- rbind.data.frame(Pclass_table, Sex_table, Embarked_table)
colnames(df_var_cualitativa_table) <- c("Variable Cualitativa", "Frecuencia Absoluta", "Frecuencia Relativa")

# Variables auxiliares para la creación de la tabla kable() de forma más automática.

# Dimensiones de cada grupo de la tabla
dim_grupo1_ = length(unique(df_var_cualitativa$Pclass))
dim_grupo2_ = length(unique(df_var_cualitativa$Sex))
dim_grupo3_ = length(unique(df_var_cualitativa$Embarked))



# Límites de las posiciones de los grupos (automatico)
dim1_i <- 1
dim1_f <- dim_grupo1_
dim2_i <- dim1_f +1
dim2_f <- dim_grupo1_ + dim_grupo2_
dim3_i <- dim2_f +1
dim3_f <- dim_grupo1_ + dim_grupo2_ + dim_grupo3_



# Formato de la tabla mediante función kable()
# Formato de los dígitos de los campos
# Creación del título de la tabla y anotación
kable(df_var_cualitativa_table, digits = c(0,0,3), caption = "-TABLA RESUMEN DE LAS VARIABLES CUALITATIVAS-
      <p> (Total observaciones: 1309. Suma de frecuencias relativas sin redondeo = 1.000)") %>%
  kable_styling("striped",
                full_width = F) %>%
  pack_rows("Clases Embarque",
            dim1_i,
            dim1_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Sexo",
            dim2_i,
            dim2_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Embarque",
            dim3_i,
            dim3_f,
            label_row_css = "background-color: #666; color: #fff;")

```





## Tabla resumen de las variables cuantitativas (datos completos)

Realizaremos una tabla resumen con los estadísticos principales de tendencia central y dispersión, con medidas robustas y no robustas.
Para ello, utilizaremos tres funciones que nos aportarán diferentes estadísticos a utilizar:

describe()
winsor.mean() (aplicaremos unos límites del 5 %).
stat.desc()
Estas tres funciones nos darán diversos estadísticos que uniremos y ordenaremos en una única tabla para mostrar un completo resumen estadístico de las variables cuantitativas.


Finalmente, creamos una tabla mediante la función kable().





```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

# Creación tabla con describe()
col_var_cuantitativa_sin_ID <- c("Age", "SibSp", "Parch", "Count.ticket", "Unit.price")

df_var_cuantitativa <- df_total_sin_etiqueta[, col_var_cuantitativa_sin_ID]

df_var_cuantitativa_tabla <- describe(df_var_cuantitativa, quant = TRUE, IQR = TRUE)

# Creación tabla con winsor.mean()
winsor <- data.frame(t(winsor.mean(df_var_cuantitativa, trim= 0.05)))
winsor_df <- data.frame(t(winsor))
colnames(winsor_df) <- c("Winsor Mean 5%")

# Unión tablas describe() con winsor.mean()
df_var_cuantitativa_tabla$Winsor_Mean_.5 <- winsor_df$`Winsor Mean 5%`

# Eliminación campos no usables
df_var_cuantitativa_tabla <- df_var_cuantitativa_tabla[, -c(1, 11, 12, 15 )]

# Cambio de nombres de los campos
colnames(df_var_cuantitativa_tabla) <- c("Number", "Mean", "St_Dev", "Median", "Trimmed_Median", "MAD", "Min", "Max", "Range", "SE_Mean", "IQR", "Winsor_Mean_0.5")

df_var_cuantitativa_tabla

```

```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

options(digits=2)

# Creación tabla con stat.desc()
df_var_cuantitativa_tabla2 <- as.data.frame(t(round(stat.desc(df_var_cuantitativa),2)))

# Cambio de nombres de los campos
colnames(df_var_cuantitativa_tabla2) <- c("tot_num", "NUll", "NA", "Min_", "Max_", "Range_", "sum", "median_", "mean_", "se_mean_", "CI_Mean_0.95", "Var", "stddev_", "Coef_Var")

# Eliminación campos no usables
df_var_cuantitativa_tabla2 <- df_var_cuantitativa_tabla2[, -c(1, 2, 4, 5, 6 ,7, 8, 9, 10, 13)]
df_var_cuantitativa_tabla2

```

```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

# Unión tablas describe()/winsor.mean() con tabla stat.desc()
counterdf_cuan <- c(1:dim(df_var_cuantitativa_tabla2)[2])
df_var_cuantitativa_tabla_dim_ini <- dim(df_var_cuantitativa_tabla)[2]

for (i in counterdf_cuan){
      df_var_cuantitativa_tabla[i+df_var_cuantitativa_tabla_dim_ini] <- df_var_cuantitativa_tabla2[i]
     }

# Reordenamiento de las columnas para poder agrupar los campos for temática: tendencia central, dispersión, robusta y no robusta
df_var_cuantitativa_tabla <- df_var_cuantitativa_tabla[, c(2, 10, 14, 4, 5, 12, 15, 16, 3, 6, 11, 1, 13, 7, 8, 9)]


# Creación del dataframe haciendo la transpuesta de la tabla anterior para tener los estadisticos en las fila y las variables en las columnas.
df_var_cuantitativa_tabla <- data.frame(t(df_var_cuantitativa_tabla))
df_var_cuantitativa_tabla

```






```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}

# Creación de la tabla mediante kable()

# Formato numérico no científico
options(scipen = 999)

# Variables auxiliares para la creación de la tabla kable() de forma más automática.
# Dimensiones de cada grupo de la tabla
dim_grupo1 = 3
dim_grupo2 = 3
dim_grupo3 = 3
dim_grupo4 = 2
dim_grupo5 = 5

# Límites de las posiciones de los grupos (automatico)
dim1_i <- 1
dim1_f <- dim_grupo1
dim2_i <- dim1_f +1
dim2_f <- dim_grupo1 + dim_grupo2
dim3_i <- dim2_f +1
dim3_f <- dim_grupo1 + dim_grupo2 + dim_grupo3
dim4_i <- dim3_f +1
dim4_f <- dim_grupo1 + dim_grupo2 + dim_grupo3 + dim_grupo4
dim5_i <- dim4_f +1
dim5_f <- dim_grupo1 + dim_grupo2 + dim_grupo3 + dim_grupo4 + dim_grupo5

# Formato de la tabla mediante función kable()
# Formato de los dígitos de los campos
# Creación del título de la tabla y anotación
kable(df_var_cuantitativa_tabla, digits = c(2, 2, 2, 3), caption = "-TABLA RESUMEN DE LAS VARIABLES CUANTITATIVAS-
      <p> (Total observaciones: 1309.)") %>%
  kable_styling("striped",  full_width = F) %>%
  pack_rows("Tendencia Central (medidas  NO robustas)",
            dim1_i,
            dim1_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Tendencia Central (medidas robustas)",
            dim2_i,
            dim2_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Dispersion (medidas NO robustas)",
            dim3_i,
            dim3_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Dispersion (medidas robustas)",
            dim4_i,
            dim4_f,
            label_row_css = "background-color: #666; color: #fff;") %>%
  pack_rows("Información Adicional", dim5_i, dim5_f ,label_row_css = "background-color: #666; color: #fff;")

```







```{r echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Creación tabla con describe()
#col_var_cuantitativa_ID <- c("Age", "SibSp", "Parch", "Fare")

#df_var_cuantitativa <- df_total_sin_etiqueta[, col_var_cuantitativa_ID]

#df_var_cuantitativa_tabla <- describe(df_var_cuantitativa, quant = TRUE, IQR = TRUE)

# Eliminación campos no usables
#df_var_cuantitativa_tabla <- df_var_cuantitativa_tabla[, -c(1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15)]

# Cambio de nombres de los campos
#colnames(df_var_cuantitativa_tabla) <- c("Mean", "St_Dev", "Median","IQR")

# Transpuesta de la matriz
#df_var_cuantitativa_tabla <- data.frame(t(df_var_cuantitativa_tabla))

```



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Selección/Filtrado de las instancias que solamente pertenecen a US
# Creación de la tabla mediante kable()

# Formato numérico no científico
#options(scipen = 999)

# Variables auxiliares para la creación de la tabla kable() de forma más automática.
# Dimensiones de cada grupo de la tabla
#dim_grupo1 = 4


# Límites de las posiciones de los grupos (automatico)
#dim1_i <- 1
#dim1_f <- dim_grupo1


# Formato de la tabla mediante función kable()
# Formato de los dígitos de los campos
# Creación del título de la tabla y anotación
#kable(df_var_cuantitativa_tabla, digits = c(2, 2, 2, 2, 2, 2, 2), caption = "TABLA RESUMEN DE LAS VARIABLES CUANTITATIVAS (Total observaciones: 400)
#            __________________________________________________________________________________
#      <p>   Sales:         Ventas unitarias, en miles, en cada ubicación
#      <p>   CompPrice:     Precio que cobra el competidor en cada ubicación
#      <p>   Income:        Nivel de ingresos comunitarios, en miles de dólares
#      <p>   Advertising:   Presupuesto de publicidad local de la empresa en cada ubicación, en miles de dólares
#      <p>   Population:    Tamaño de la población en la región, en miles
#      <p>   Price:         Precio del producto en cada ubicación
#      <p>   Age:           Edad media de la población local") %>%
#  
#  kable_styling("striped",  full_width = T) %>%
#  pack_rows("Datos Cuantitativos",
#            dim1_i,
#            dim1_f,
#            label_row_css = "background-color: #666; color: #fff;")
```

******
# **Resolución del problema**
******  




******
# **Creación del archivo preprocesado**
******

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Guardamos el archivo con el nombre Titanic_processed.csv
#write.csv(df, "Titanic_processed.csv", row.names = FALSE)
```


<br>



```{r}
contrib <- data.frame(rbind(c("Investigación Previa", "Olga Garcés / Carlos Acosta"),
                            c("Redacción de las respuestas", "Olga Garcés / Carlos Acosta"),
                            c("Desarrollo código", "Olga Garcés / Carlos Acosta")))
colnames(contrib) <- c("Contribuciones", "Firma")

contrib
```



